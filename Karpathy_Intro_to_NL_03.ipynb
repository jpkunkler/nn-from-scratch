{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all words\n",
    "words = open(\"names.txt\").read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# mapping from each letter to integer and vice versa\n",
    "chars = sorted(list(set(\"\".join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi[\".\"] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # context_length; how many characters do we use to support our prediction of the next character?\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size # padded context of 0-tokens (i.e. \".\")\n",
    "    for ch in w + \".\":\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(\"\".join(itos[i] for i in context), \"--->\", itos[ix])\n",
    "        context = context[1:] + [ix] # shift/move the context window one character to the right --> rolling window of context\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 32 Input character sequences of block size 3 for these 5 Words\n",
    "# Each of these 32 sequences is represented by 3 integers (one index for each character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 15],\n",
       "        [ 0, 15, 12],\n",
       "        [15, 12,  9],\n",
       "        [12,  9, 22],\n",
       "        [ 9, 22,  9],\n",
       "        [22,  9,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0,  1, 22],\n",
       "        [ 1, 22,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  9],\n",
       "        [ 0,  9, 19],\n",
       "        [ 9, 19,  1],\n",
       "        [19,  1,  2],\n",
       "        [ 1,  2,  5],\n",
       "        [ 2,  5, 12],\n",
       "        [ 5, 12, 12],\n",
       "        [12, 12,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 19],\n",
       "        [ 0, 19, 15],\n",
       "        [19, 15, 16],\n",
       "        [15, 16,  8],\n",
       "        [16,  8,  9],\n",
       "        [ 8,  9,  1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the embedding space and initialize it randomly\n",
    "# Here, we start by embedding all 27 characters in as small as 2 dimensions, i.e. a 2-dimensional space\n",
    "C = torch.randn((27, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2401, -0.0377])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start by an individual example, i.e. character 5\n",
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0725,  0.6984],\n",
       "        [-2.0324,  0.1152],\n",
       "        [ 1.2419, -1.9337],\n",
       "        [ 0.6401,  0.7690],\n",
       "        [-0.3368, -1.5828],\n",
       "        [ 1.2401, -0.0377],\n",
       "        [ 1.6449,  1.4060],\n",
       "        [ 0.2537,  1.3225],\n",
       "        [ 0.2521,  0.0083],\n",
       "        [-1.7709, -0.2120],\n",
       "        [-0.9364, -1.3593],\n",
       "        [-1.2271, -0.3828],\n",
       "        [-0.4699, -0.6034],\n",
       "        [ 1.1369, -0.8860],\n",
       "        [-0.1748,  1.5073],\n",
       "        [-0.8042,  1.1424],\n",
       "        [ 1.3403,  0.3918],\n",
       "        [ 0.7747, -0.4452],\n",
       "        [-2.1699, -0.6762],\n",
       "        [ 0.3731, -0.4980],\n",
       "        [ 0.1442, -1.2048],\n",
       "        [-0.9659, -0.1710],\n",
       "        [-1.4328, -1.9461],\n",
       "        [-0.8252, -0.2312],\n",
       "        [ 0.0157,  0.3363],\n",
       "        [ 0.5891, -0.8919],\n",
       "        [ 0.3722, -0.1270]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each alphabetic character is represented by a 2D vector\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2401, -0.0377])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using one-hot encoding --> the results are identical!!\n",
    "# i.e. we can index for the vecto representation of each character using its one-hot encoding\n",
    "# since all 0 values in the encoding will serve as masks and only the 1 active bit will be used in the dot product\n",
    "F.one_hot(torch.tensor(5), num_classes=27).float() @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2401, -0.0377],\n",
       "        [ 1.6449,  1.4060],\n",
       "        [ 0.2537,  1.3225],\n",
       "        [ 0.2537,  1.3225],\n",
       "        [ 0.2537,  1.3225],\n",
       "        [ 0.2537,  1.3225]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will continue by simply using the Index method C[5] instead of the One Hot Encoder because its faster to write\n",
    "# NOTE: Python Indexing is incredibly flexible\n",
    "# We can index using integers, lists and even tensors. We can even repeatedly index the same element\n",
    "C[torch.tensor([5,6,7, 7, 7, 7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 15],\n",
       "        [ 0, 15, 12],\n",
       "        [15, 12,  9],\n",
       "        [12,  9, 22],\n",
       "        [ 9, 22,  9],\n",
       "        [22,  9,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0,  1, 22],\n",
       "        [ 1, 22,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  9],\n",
       "        [ 0,  9, 19],\n",
       "        [ 9, 19,  1],\n",
       "        [19,  1,  2],\n",
       "        [ 1,  2,  5],\n",
       "        [ 2,  5, 12],\n",
       "        [ 5, 12, 12],\n",
       "        [12, 12,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 19],\n",
       "        [ 0, 19, 15],\n",
       "        [19, 15, 16],\n",
       "        [15, 16,  8],\n",
       "        [16,  8,  9],\n",
       "        [ 8,  9,  1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0725,  0.6984],\n",
       "         [-0.0725,  0.6984],\n",
       "         [-0.0725,  0.6984]],\n",
       "\n",
       "        [[-0.0725,  0.6984],\n",
       "         [-0.0725,  0.6984],\n",
       "         [ 1.2401, -0.0377]],\n",
       "\n",
       "        [[-0.0725,  0.6984],\n",
       "         [ 1.2401, -0.0377],\n",
       "         [ 1.1369, -0.8860]],\n",
       "\n",
       "        [[ 1.2401, -0.0377],\n",
       "         [ 1.1369, -0.8860],\n",
       "         [ 1.1369, -0.8860]],\n",
       "\n",
       "        [[ 1.1369, -0.8860],\n",
       "         [ 1.1369, -0.8860],\n",
       "         [-2.0324,  0.1152]],\n",
       "\n",
       "        [[-0.0725,  0.6984],\n",
       "         [-0.0725,  0.6984],\n",
       "         [-0.0725,  0.6984]],\n",
       "\n",
       "        [[-0.0725,  0.6984],\n",
       "         [-0.0725,  0.6984],\n",
       "         [-0.8042,  1.1424]],\n",
       "\n",
       "        [[-0.0725,  0.6984],\n",
       "         [-0.8042,  1.1424],\n",
       "         [-0.4699, -0.6034]],\n",
       "\n",
       "        [[-0.8042,  1.1424],\n",
       "         [-0.4699, -0.6034],\n",
       "         [-1.7709, -0.2120]],\n",
       "\n",
       "        [[-0.4699, -0.6034],\n",
       "         [-1.7709, -0.2120],\n",
       "         [-1.4328, -1.9461]],\n",
       "\n",
       "        [[-1.7709, -0.2120],\n",
       "         [-1.4328, -1.9461],\n",
       "         [-1.7709, -0.2120]],\n",
       "\n",
       "        [[-1.4328, -1.9461],\n",
       "         [-1.7709, -0.2120],\n",
       "         [-2.0324,  0.1152]],\n",
       "\n",
       "        [[-0.0725,  0.6984],\n",
       "         [-0.0725,  0.6984],\n",
       "         [-0.0725,  0.6984]],\n",
       "\n",
       "        [[-0.0725,  0.6984],\n",
       "         [-0.0725,  0.6984],\n",
       "         [-2.0324,  0.1152]],\n",
       "\n",
       "        [[-0.0725,  0.6984],\n",
       "         [-2.0324,  0.1152],\n",
       "         [-1.4328, -1.9461]],\n",
       "\n",
       "        [[-2.0324,  0.1152],\n",
       "         [-1.4328, -1.9461],\n",
       "         [-2.0324,  0.1152]],\n",
       "\n",
       "        [[-0.0725,  0.6984],\n",
       "         [-0.0725,  0.6984],\n",
       "         [-0.0725,  0.6984]],\n",
       "\n",
       "        [[-0.0725,  0.6984],\n",
       "         [-0.0725,  0.6984],\n",
       "         [-1.7709, -0.2120]],\n",
       "\n",
       "        [[-0.0725,  0.6984],\n",
       "         [-1.7709, -0.2120],\n",
       "         [ 0.3731, -0.4980]],\n",
       "\n",
       "        [[-1.7709, -0.2120],\n",
       "         [ 0.3731, -0.4980],\n",
       "         [-2.0324,  0.1152]],\n",
       "\n",
       "        [[ 0.3731, -0.4980],\n",
       "         [-2.0324,  0.1152],\n",
       "         [ 1.2419, -1.9337]],\n",
       "\n",
       "        [[-2.0324,  0.1152],\n",
       "         [ 1.2419, -1.9337],\n",
       "         [ 1.2401, -0.0377]],\n",
       "\n",
       "        [[ 1.2419, -1.9337],\n",
       "         [ 1.2401, -0.0377],\n",
       "         [-0.4699, -0.6034]],\n",
       "\n",
       "        [[ 1.2401, -0.0377],\n",
       "         [-0.4699, -0.6034],\n",
       "         [-0.4699, -0.6034]],\n",
       "\n",
       "        [[-0.4699, -0.6034],\n",
       "         [-0.4699, -0.6034],\n",
       "         [-2.0324,  0.1152]],\n",
       "\n",
       "        [[-0.0725,  0.6984],\n",
       "         [-0.0725,  0.6984],\n",
       "         [-0.0725,  0.6984]],\n",
       "\n",
       "        [[-0.0725,  0.6984],\n",
       "         [-0.0725,  0.6984],\n",
       "         [ 0.3731, -0.4980]],\n",
       "\n",
       "        [[-0.0725,  0.6984],\n",
       "         [ 0.3731, -0.4980],\n",
       "         [-0.8042,  1.1424]],\n",
       "\n",
       "        [[ 0.3731, -0.4980],\n",
       "         [-0.8042,  1.1424],\n",
       "         [ 1.3403,  0.3918]],\n",
       "\n",
       "        [[-0.8042,  1.1424],\n",
       "         [ 1.3403,  0.3918],\n",
       "         [ 0.2521,  0.0083]],\n",
       "\n",
       "        [[ 1.3403,  0.3918],\n",
       "         [ 0.2521,  0.0083],\n",
       "         [-1.7709, -0.2120]],\n",
       "\n",
       "        [[ 0.2521,  0.0083],\n",
       "         [-1.7709, -0.2120],\n",
       "         [-2.0324,  0.1152]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can even index using 2D tensors\n",
    "C[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X].shape # for each of the original [32, 3] tensor entries, retrieve and add the 2D embedding vector as additional dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[13, 2] # give me the third character for the 13th sequence, which should be \"a\" or index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.0324,  0.1152])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X][13,2] # please give me the vector encoding of the character \"a\" found in the third character of the 13th sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.0324,  0.1152])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[1] # which is identical to the value of our lookup table at position index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EMBEDDING ------------->>>\n",
    "emb = C[X] # embed all input sequences simultaneously\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING UP THE NEURAL NETWORK LAYER 1 ---------->>>\n",
    "# For each input, we have a sequence of three characters, where each character is embedded in a 2D Vector\n",
    "# Therefore, as input our network will receive 2 floats per character, for 3 characters = 3*2 = 6 Input values\n",
    "# In short: We have 2D embeddings and we have three of them\n",
    "W1 = torch.rand((6, 100)) # initialize weights for the first layer; 6 = 3 * 2 as Inputs and 100 neurons in hidden layer\n",
    "b1 = torch.rand(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape # this does not work as we need [32, 6] as our input; see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will result in an error since the dimensions do not match up\n",
    "# emb @ W1 + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short excourse on pyTorch Tensor Storage and the .view() operation\n",
    "# In order to reshape arrays efficiently\n",
    "# http://blog.ezyang.com/2019/05/pytorch-internals/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to concatonate our dimensions\n",
    "# i.e. we need to pull out the individual embedding vectors for each of the three characters in a sequence\n",
    "# and do this for each of our 32 input samples\n",
    "# and then concatonate them together to receive a tensor [ch1_v1, ch1_v2, ch2_v1, ch2_v2, ch3_v1, ch3_v2]\n",
    "# which has the required input shape of [32, 6]\n",
    "# NOTE: This solution is ugly as it does not generalize!!! This only works for block_size = 3\n",
    "torch.concat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try the same thing in a general manner\n",
    "torch.cat(torch.unbind(emb, 1), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1],\n",
       "        [ 2,  3],\n",
       "        [ 4,  5],\n",
       "        [ 6,  7],\n",
       "        [ 8,  9],\n",
       "        [10, 11],\n",
       "        [12, 13],\n",
       "        [14, 15],\n",
       "        [16, 17]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(9,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 6,  7],\n",
       "         [ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15],\n",
       "         [16, 17]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as long as the total number of elements stays the same, i.e. 3*3*2 = 18 and 9*2 = 18 and 18*1 = 18 \n",
    "# we can arbitrarily decide the shape we want our tensor to have\n",
    "a.view(3,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/0_59jbfj3ysfnnbc0x5qr4z00000gp/T/ipykernel_66998/3687906448.py:4: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  a.storage()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 18]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each tensor is always represented as a 1D array in the computer memory\n",
    "# therefore, the .view() operation is extremely efficient, as it does not change the memory\n",
    "# but only the representation that our values in memory will have\n",
    "a.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " 1.240068793296814\n",
       " -0.03771159425377846\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " 1.240068793296814\n",
       " -0.03771159425377846\n",
       " 1.136930227279663\n",
       " -0.8860231041908264\n",
       " 1.240068793296814\n",
       " -0.03771159425377846\n",
       " 1.136930227279663\n",
       " -0.8860231041908264\n",
       " 1.136930227279663\n",
       " -0.8860231041908264\n",
       " 1.136930227279663\n",
       " -0.8860231041908264\n",
       " 1.136930227279663\n",
       " -0.8860231041908264\n",
       " -2.0324151515960693\n",
       " 0.1152297705411911\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.8042418360710144\n",
       " 1.1424105167388916\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.8042418360710144\n",
       " 1.1424105167388916\n",
       " -0.46989089250564575\n",
       " -0.6033931970596313\n",
       " -0.8042418360710144\n",
       " 1.1424105167388916\n",
       " -0.46989089250564575\n",
       " -0.6033931970596313\n",
       " -1.7709338665008545\n",
       " -0.21196486055850983\n",
       " -0.46989089250564575\n",
       " -0.6033931970596313\n",
       " -1.7709338665008545\n",
       " -0.21196486055850983\n",
       " -1.4327961206436157\n",
       " -1.9460760354995728\n",
       " -1.7709338665008545\n",
       " -0.21196486055850983\n",
       " -1.4327961206436157\n",
       " -1.9460760354995728\n",
       " -1.7709338665008545\n",
       " -0.21196486055850983\n",
       " -1.4327961206436157\n",
       " -1.9460760354995728\n",
       " -1.7709338665008545\n",
       " -0.21196486055850983\n",
       " -2.0324151515960693\n",
       " 0.1152297705411911\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -2.0324151515960693\n",
       " 0.1152297705411911\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -2.0324151515960693\n",
       " 0.1152297705411911\n",
       " -1.4327961206436157\n",
       " -1.9460760354995728\n",
       " -2.0324151515960693\n",
       " 0.1152297705411911\n",
       " -1.4327961206436157\n",
       " -1.9460760354995728\n",
       " -2.0324151515960693\n",
       " 0.1152297705411911\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -1.7709338665008545\n",
       " -0.21196486055850983\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -1.7709338665008545\n",
       " -0.21196486055850983\n",
       " 0.3731137812137604\n",
       " -0.4980236291885376\n",
       " -1.7709338665008545\n",
       " -0.21196486055850983\n",
       " 0.3731137812137604\n",
       " -0.4980236291885376\n",
       " -2.0324151515960693\n",
       " 0.1152297705411911\n",
       " 0.3731137812137604\n",
       " -0.4980236291885376\n",
       " -2.0324151515960693\n",
       " 0.1152297705411911\n",
       " 1.241900086402893\n",
       " -1.9337449073791504\n",
       " -2.0324151515960693\n",
       " 0.1152297705411911\n",
       " 1.241900086402893\n",
       " -1.9337449073791504\n",
       " 1.240068793296814\n",
       " -0.03771159425377846\n",
       " 1.241900086402893\n",
       " -1.9337449073791504\n",
       " 1.240068793296814\n",
       " -0.03771159425377846\n",
       " -0.46989089250564575\n",
       " -0.6033931970596313\n",
       " 1.240068793296814\n",
       " -0.03771159425377846\n",
       " -0.46989089250564575\n",
       " -0.6033931970596313\n",
       " -0.46989089250564575\n",
       " -0.6033931970596313\n",
       " -0.46989089250564575\n",
       " -0.6033931970596313\n",
       " -0.46989089250564575\n",
       " -0.6033931970596313\n",
       " -2.0324151515960693\n",
       " 0.1152297705411911\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " 0.3731137812137604\n",
       " -0.4980236291885376\n",
       " -0.07254821062088013\n",
       " 0.6984353065490723\n",
       " 0.3731137812137604\n",
       " -0.4980236291885376\n",
       " -0.8042418360710144\n",
       " 1.1424105167388916\n",
       " 0.3731137812137604\n",
       " -0.4980236291885376\n",
       " -0.8042418360710144\n",
       " 1.1424105167388916\n",
       " 1.3403455018997192\n",
       " 0.39176419377326965\n",
       " -0.8042418360710144\n",
       " 1.1424105167388916\n",
       " 1.3403455018997192\n",
       " 0.39176419377326965\n",
       " 0.25213125348091125\n",
       " 0.008274498395621777\n",
       " 1.3403455018997192\n",
       " 0.39176419377326965\n",
       " 0.25213125348091125\n",
       " 0.008274498395621777\n",
       " -1.7709338665008545\n",
       " -0.21196486055850983\n",
       " 0.25213125348091125\n",
       " 0.008274498395621777\n",
       " -1.7709338665008545\n",
       " -0.21196486055850983\n",
       " -2.0324151515960693\n",
       " 0.1152297705411911\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 192]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pyTorch Tensors are ALWAYS stored as 1D, single-dimension \"lists\" in memory!!!\n",
    "# every shape is therefore artificial\n",
    "emb.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long story short, we can do the following in order for our dot product to work:\n",
    "# We need [32, 6] * [6, 100] + [100]\n",
    "# and this will give us the hidden states for our 100 Neurons in our hidden layer that we are after\n",
    "\n",
    "# h = emb.view(32,6) @ W1 + b1 # hard-coded dimensions\n",
    "# h = emb.view(emb.shape[0], 6) @ W1 + b1 # dynamic dimensions\n",
    "h = emb.view(-1, 6) @ W1 + b1 # inferred dimensions, as the number of dimensions has to stay the same (see abobe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When adding the bias vector, check the broadcasting logic!!\n",
    "\n",
    "# Rule One: Align on the right\n",
    "# [32, 100]\n",
    "# [  , 100]\n",
    "\n",
    "# Rule two: check that all dimensions are either equal, one of them is 1 or one of them is None\n",
    "# --> True\n",
    "\n",
    "# Rule three: Fill up open dimensions by 1\n",
    "# [32, 100]\n",
    "# [ 1, 100]\n",
    "\n",
    "# HERE, THE BIAS VECTOR WILL BROADCAST/COPY VERTICALLY AND ADD PERFORM ELEMENT-WISE ADDITION\n",
    "# THEREFORE ADDING THE SAME BIAS TO ALL OF OUR NEURONS \n",
    "# THIS IS CORRECT AND THE BEHAVIOR WE WATN!! Good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = h.tanh() # apply hyperbolic tangent to transform each value to between -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6622e-08, 2.9352e-08, 1.6705e-06, 3.3116e-09, 1.4103e-05, 1.7486e-06,\n",
       "        1.0097e-09, 2.1496e-03, 1.1542e-09, 1.1598e-02, 7.9932e-07, 4.8496e-10,\n",
       "        2.0617e-08, 6.4601e-06, 2.7171e-08, 4.3480e-10, 8.1027e-11, 2.8212e-01,\n",
       "        1.4802e-06, 1.5983e-13, 1.1818e-03, 7.7408e-03, 4.0084e-03, 4.4328e-07,\n",
       "        1.1442e-09, 4.4271e-07, 6.4881e-07, 1.1285e-09, 5.9513e-12, 3.5976e-12,\n",
       "        1.3910e-05, 1.0661e-09])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the prediction of the network for the ACTUAL character we saved in Y\n",
    "prob[torch.arange(X.shape[0]), Y] # for each row of inputs, extract the probability at the correct index of Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -prob[torch.arange(X.shape[0]), Y].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.6801)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now refactor our code :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(42)\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.nelement() for p in parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = C[X] # [32, 3, 2]\n",
    "h = torch.tanh(emb.view(-1, 6) @W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "# counts = logits.exp()\n",
    "# prob = counts / counts.sum(1, keepdim=True)\n",
    "# loss = -prob[torch.arange(X.shape[0]), Y].log().mean() # Negative Log Likelihood\n",
    "loss = F.cross_entropy(logits, Y) # even better and more efficient than the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7758)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.8298e-04, 4.1998e-02, 1.1416e-01, 8.4356e-01])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case in Point of why F.cross_entropy() is superior to manual implementation\n",
    "logits = torch.tensor([-5, 0, 1, 3])\n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum()\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4013e-45, 4.2010e-02, 1.1420e-01, 8.4379e-01])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case in Point of why F.cross_entropy() is superior to manual implementation\n",
    "# Large negative numbers will be fine, since these will result in very small values converging to 0\n",
    "logits = torch.tensor([-100, 0, 1, 3])\n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum()\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., nan])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case in Point of why F.cross_entropy() is superior to manual implementation\n",
    "# but here lies the issue with large POSITIVE numbers since we will run out of memory on our floating point numbers\n",
    "# resulting in Not a Number issues\n",
    "logits = torch.tensor([-100, 0, 1, 100])\n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum()\n",
    "prob\n",
    "\n",
    "# LEARN: NEGATIVE NUMBERS ARE OKAY WHILE POSITIVE NUMBERS CAN POTENTIALLY OVERFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 3.7835e-44, 1.0089e-43, 1.0000e+00])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case in Point of why F.cross_entropy() is superior to manual implementation\n",
    "# PyTorch solves this elegantly within the cross_entropy() function\n",
    "# because it turns out that we can arbitrarily add or subtract a constant to our logits and the result stays the same\n",
    "# what pyTorch does it it \"normalizes\" the largest value by subtracting it, i.e. subtracting 100\n",
    "# therefore, the largest number will become 0 and all othe values will become negative\n",
    "# but since negative values are fine, we will never run into overflow issues\n",
    "# therefore, the result will always be mathematically well-behaved\n",
    "logits = torch.tensor([-100, 0, 1, 100]) - 100\n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum()\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good reasons to call cross_entropy()\n",
    "# 1. It uses a fused kernel, therefore the forward pass will be much more efficient.\n",
    "# 2. It uses a fused kernel, therefore the backpropagation will be much more efficient.\n",
    "# 3. It will always create numerically well-behaved results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26498541235923767\n",
      "0.2649219036102295\n",
      "0.26485905051231384\n",
      "0.26479673385620117\n",
      "0.26473504304885864\n",
      "0.26467394828796387\n",
      "0.26461338996887207\n",
      "0.264553427696228\n",
      "0.26449406147003174\n",
      "0.26443517208099365\n",
      "0.26437678933143616\n",
      "0.2643190622329712\n",
      "0.26426181197166443\n",
      "0.26420506834983826\n",
      "0.2641488313674927\n",
      "0.2640931308269501\n",
      "0.2640378773212433\n",
      "0.2639831602573395\n",
      "0.2639288902282715\n",
      "0.26387515664100647\n",
      "0.26382187008857727\n",
      "0.2637689709663391\n",
      "0.2637166678905487\n",
      "0.26366475224494934\n",
      "0.2636132836341858\n",
      "0.26356223225593567\n",
      "0.26351162791252136\n",
      "0.26346153020858765\n",
      "0.2634117603302002\n",
      "0.26336243748664856\n",
      "0.26331353187561035\n",
      "0.2632650136947632\n",
      "0.26321691274642944\n",
      "0.2631692588329315\n",
      "0.26312193274497986\n",
      "0.2630750238895416\n",
      "0.26302850246429443\n",
      "0.2629823684692383\n",
      "0.2629365622997284\n",
      "0.26289117336273193\n",
      "0.26284611225128174\n",
      "0.2628014385700226\n",
      "0.2627570331096649\n",
      "0.26271310448646545\n",
      "0.2626694440841675\n",
      "0.26262614130973816\n",
      "0.2625831961631775\n",
      "0.26254063844680786\n",
      "0.2624983489513397\n",
      "0.26245635747909546\n",
      "0.26241469383239746\n",
      "0.2623733878135681\n",
      "0.26233237981796265\n",
      "0.26229172945022583\n",
      "0.2622513175010681\n",
      "0.26221126317977905\n",
      "0.26217150688171387\n",
      "0.2621319890022278\n",
      "0.26209282875061035\n",
      "0.2620539367198944\n",
      "0.26201531291007996\n",
      "0.2619769871234894\n",
      "0.26193901896476746\n",
      "0.26190119981765747\n",
      "0.26186370849609375\n",
      "0.2618265151977539\n",
      "0.26178956031799316\n",
      "0.2617528736591339\n",
      "0.26171645522117615\n",
      "0.2616802752017975\n",
      "0.2616443932056427\n",
      "0.261608749628067\n",
      "0.26157331466674805\n",
      "0.26153820753097534\n",
      "0.26150327920913696\n",
      "0.26146870851516724\n",
      "0.26143425703048706\n",
      "0.2614000737667084\n",
      "0.26136618852615356\n",
      "0.2613324522972107\n",
      "0.2612989544868469\n",
      "0.26126572489738464\n",
      "0.2612327039241791\n",
      "0.2611998915672302\n",
      "0.2611673176288605\n",
      "0.2611349821090698\n",
      "0.2611028254032135\n",
      "0.2610709071159363\n",
      "0.26103919744491577\n",
      "0.26100772619247437\n",
      "0.2609764039516449\n",
      "0.26094532012939453\n",
      "0.26091447472572327\n",
      "0.26088377833366394\n",
      "0.2608533203601837\n",
      "0.26082301139831543\n",
      "0.26079294085502625\n",
      "0.2607630491256714\n",
      "0.26073336601257324\n",
      "0.2607038617134094\n"
     ]
    }
   ],
   "source": [
    "# NOTE: We are fitting our model on only 32 examples\n",
    "# by using 3481 parameters\n",
    "# therefore, we are heavily overfitting our data\n",
    "for _ in range(100):\n",
    "    # forward pass\n",
    "    emb = C[X] # [32, 3, 2]\n",
    "    h = torch.tanh(emb.view(-1, 6) @W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y) # even better and more efficient than the above\n",
    "\n",
    "    # backward pass / backpropagation\n",
    "    for p in parameters:\n",
    "        p.grad = None # don't forget to .zero_grad() !!!\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    learning_rate = 0.1\n",
    "    for p in parameters:\n",
    "        p.data += -learning_rate * p.grad \n",
    "    \n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([10.0510, 13.5870, 12.2906, 13.9351, 20.5013, 10.0510, 13.7941, 18.0906,\n",
       "        11.1204, 14.8780,  9.9988, 20.4743, 10.0510, 15.6657, 12.2923, 16.6557,\n",
       "        10.0510, 10.7647, 12.8409, 15.3040, 15.6337, 14.8731, 17.8228, 15.1672,\n",
       "        17.6074, 10.0510, 11.9149, 12.4183, 13.2719, 16.4624, 11.8989, 22.0096],\n",
       "       grad_fn=<MaxBackward0>),\n",
       "indices=tensor([19, 13, 13,  1,  0, 19, 12,  9, 22,  9,  1,  0, 19, 22,  1,  0, 19, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # context_length; how many characters do we use to support our prediction of the next character?\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words:\n",
    "    context = [0] * block_size # padded context of 0-tokens (i.e. \".\")\n",
    "    for ch in w + \".\":\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        context = context[1:] + [ix] # shift/move the context window one character to the right --> rolling window of context\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(42)\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.nelement() for p in parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.72646713256836\n",
      "14.942943572998047\n",
      "13.863018989562988\n",
      "13.003837585449219\n",
      "12.292214393615723\n",
      "11.732643127441406\n",
      "11.270574569702148\n",
      "10.859721183776855\n",
      "10.479723930358887\n",
      "10.136445045471191\n",
      "9.829903602600098\n",
      "9.552262306213379\n",
      "9.297037124633789\n",
      "9.060540199279785\n",
      "8.8405179977417\n",
      "8.635120391845703\n",
      "8.442394256591797\n",
      "8.260418891906738\n",
      "8.087592124938965\n",
      "7.922700881958008\n",
      "7.764862060546875\n",
      "7.613436698913574\n",
      "7.467946529388428\n",
      "7.3280229568481445\n",
      "7.193362236022949\n",
      "7.063704490661621\n",
      "6.938810348510742\n",
      "6.818456172943115\n",
      "6.702428340911865\n",
      "6.590520858764648\n",
      "6.482547283172607\n",
      "6.378341197967529\n",
      "6.277759075164795\n",
      "6.180685520172119\n",
      "6.087019920349121\n",
      "5.996680736541748\n",
      "5.909584999084473\n",
      "5.825646877288818\n",
      "5.7447710037231445\n",
      "5.666844844818115\n",
      "5.591747283935547\n",
      "5.519347190856934\n",
      "5.449517726898193\n",
      "5.382129669189453\n",
      "5.3170695304870605\n",
      "5.25422477722168\n",
      "5.193495750427246\n",
      "5.134785175323486\n",
      "5.078001022338867\n",
      "5.023053169250488\n",
      "4.969858169555664\n",
      "4.918334007263184\n",
      "4.868406772613525\n",
      "4.820007801055908\n",
      "4.773073673248291\n",
      "4.727549076080322\n",
      "4.683382987976074\n",
      "4.640531063079834\n",
      "4.598949432373047\n",
      "4.558603763580322\n",
      "4.51945686340332\n",
      "4.481476783752441\n",
      "4.444631099700928\n",
      "4.408888816833496\n",
      "4.374218940734863\n",
      "4.340590476989746\n",
      "4.3079729080200195\n",
      "4.276334285736084\n",
      "4.245644569396973\n",
      "4.2158732414245605\n",
      "4.186990737915039\n",
      "4.158966541290283\n",
      "4.131771564483643\n",
      "4.1053786277771\n",
      "4.07975959777832\n",
      "4.054888725280762\n",
      "4.0307393074035645\n",
      "4.00728702545166\n",
      "3.984506845474243\n",
      "3.9623754024505615\n",
      "3.9408693313598633\n",
      "3.919965982437134\n",
      "3.899644136428833\n",
      "3.8798811435699463\n",
      "3.860656499862671\n",
      "3.8419485092163086\n",
      "3.8237385749816895\n",
      "3.806006669998169\n",
      "3.7887332439422607\n",
      "3.7719013690948486\n",
      "3.7554917335510254\n",
      "3.7394890785217285\n",
      "3.7238757610321045\n",
      "3.708637237548828\n",
      "3.6937572956085205\n",
      "3.6792218685150146\n",
      "3.6650173664093018\n",
      "3.6511306762695312\n",
      "3.6375491619110107\n",
      "3.624260902404785\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Running this on the entire dataset is really slow since we are always feeding ALL the data through our forward and backward passes\n",
    "for _ in range(100):\n",
    "    # forward pass\n",
    "    emb = C[X] # [228k, 3, 2]\n",
    "    h = torch.tanh(emb.view(-1, 6) @W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y) # even better and more efficient than the above\n",
    "\n",
    "    # backward pass / backpropagation\n",
    "    for p in parameters:\n",
    "        p.grad = None # don't forget to .zero_grad() !!!\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    learning_rate = 0.1\n",
    "    for p in parameters:\n",
    "        p.data += -learning_rate * p.grad \n",
    "    \n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Batch Logic (Minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(42)\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random batches and only feed these batches forward and backward through the model\n",
    "for _ in range(10000):\n",
    "\n",
    "    # construct minibatch\n",
    "    ix = torch.randint(0, X.shape[0], (32,)) # Select 32 random indices from our dataset\n",
    "\n",
    "    X_batch = X[ix]\n",
    "    Y_batch = Y[ix]\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[X_batch] # using minibatches, we are back to [32, 3, 2]\n",
    "    h = torch.tanh(emb.view(-1, 6) @W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y_batch) # even better and more efficient than the above\n",
    "\n",
    "    # backward pass / backpropagation\n",
    "    for p in parameters:\n",
    "        p.grad = None # don't forget to .zero_grad() !!!\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    learning_rate = 0.1\n",
    "    for p in parameters:\n",
    "        p.data += -learning_rate * p.grad \n",
    "    \n",
    "    # print(loss.item()) # NOTE: In this case, this is only the loss for the current batch!!! Not the global loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4678, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global loss\n",
    "emb = C[X] # using minibatches, we are back to [32, 3, 2]\n",
    "h = torch.tanh(emb.view(-1, 6) @W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Y) # even better and more efficient than the above\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing dynamic learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(42)\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you choose a good learning rate?\n",
    "# You don't, you simply try it out, then plot it and find the best one\n",
    "lre = torch.linspace(-3, 0, 1000) # 1000 values evenly divided between -3 and 0 to pass into our exponent\n",
    "lrs = 10**lre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0011,\n",
       "        0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011,\n",
       "        0.0011, 0.0011, 0.0011, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012,\n",
       "        0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0013, 0.0013, 0.0013,\n",
       "        0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0014,\n",
       "        0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014,\n",
       "        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n",
       "        0.0015, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016,\n",
       "        0.0016, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017,\n",
       "        0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0019,\n",
       "        0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0020, 0.0020,\n",
       "        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0021, 0.0021, 0.0021, 0.0021,\n",
       "        0.0021, 0.0021, 0.0021, 0.0022, 0.0022, 0.0022, 0.0022, 0.0022, 0.0022,\n",
       "        0.0022, 0.0023, 0.0023, 0.0023, 0.0023, 0.0023, 0.0023, 0.0024, 0.0024,\n",
       "        0.0024, 0.0024, 0.0024, 0.0024, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
       "        0.0025, 0.0026, 0.0026, 0.0026, 0.0026, 0.0026, 0.0027, 0.0027, 0.0027,\n",
       "        0.0027, 0.0027, 0.0027, 0.0028, 0.0028, 0.0028, 0.0028, 0.0028, 0.0029,\n",
       "        0.0029, 0.0029, 0.0029, 0.0029, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
       "        0.0031, 0.0031, 0.0031, 0.0031, 0.0032, 0.0032, 0.0032, 0.0032, 0.0032,\n",
       "        0.0033, 0.0033, 0.0033, 0.0033, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034,\n",
       "        0.0035, 0.0035, 0.0035, 0.0035, 0.0036, 0.0036, 0.0036, 0.0036, 0.0037,\n",
       "        0.0037, 0.0037, 0.0037, 0.0038, 0.0038, 0.0038, 0.0039, 0.0039, 0.0039,\n",
       "        0.0039, 0.0040, 0.0040, 0.0040, 0.0040, 0.0041, 0.0041, 0.0041, 0.0042,\n",
       "        0.0042, 0.0042, 0.0042, 0.0043, 0.0043, 0.0043, 0.0044, 0.0044, 0.0044,\n",
       "        0.0045, 0.0045, 0.0045, 0.0045, 0.0046, 0.0046, 0.0046, 0.0047, 0.0047,\n",
       "        0.0047, 0.0048, 0.0048, 0.0048, 0.0049, 0.0049, 0.0049, 0.0050, 0.0050,\n",
       "        0.0050, 0.0051, 0.0051, 0.0051, 0.0052, 0.0052, 0.0053, 0.0053, 0.0053,\n",
       "        0.0054, 0.0054, 0.0054, 0.0055, 0.0055, 0.0056, 0.0056, 0.0056, 0.0057,\n",
       "        0.0057, 0.0058, 0.0058, 0.0058, 0.0059, 0.0059, 0.0060, 0.0060, 0.0060,\n",
       "        0.0061, 0.0061, 0.0062, 0.0062, 0.0062, 0.0063, 0.0063, 0.0064, 0.0064,\n",
       "        0.0065, 0.0065, 0.0066, 0.0066, 0.0067, 0.0067, 0.0067, 0.0068, 0.0068,\n",
       "        0.0069, 0.0069, 0.0070, 0.0070, 0.0071, 0.0071, 0.0072, 0.0072, 0.0073,\n",
       "        0.0073, 0.0074, 0.0074, 0.0075, 0.0075, 0.0076, 0.0076, 0.0077, 0.0077,\n",
       "        0.0078, 0.0079, 0.0079, 0.0080, 0.0080, 0.0081, 0.0081, 0.0082, 0.0082,\n",
       "        0.0083, 0.0084, 0.0084, 0.0085, 0.0085, 0.0086, 0.0086, 0.0087, 0.0088,\n",
       "        0.0088, 0.0089, 0.0090, 0.0090, 0.0091, 0.0091, 0.0092, 0.0093, 0.0093,\n",
       "        0.0094, 0.0095, 0.0095, 0.0096, 0.0097, 0.0097, 0.0098, 0.0099, 0.0099,\n",
       "        0.0100, 0.0101, 0.0101, 0.0102, 0.0103, 0.0104, 0.0104, 0.0105, 0.0106,\n",
       "        0.0106, 0.0107, 0.0108, 0.0109, 0.0109, 0.0110, 0.0111, 0.0112, 0.0112,\n",
       "        0.0113, 0.0114, 0.0115, 0.0116, 0.0116, 0.0117, 0.0118, 0.0119, 0.0120,\n",
       "        0.0121, 0.0121, 0.0122, 0.0123, 0.0124, 0.0125, 0.0126, 0.0127, 0.0127,\n",
       "        0.0128, 0.0129, 0.0130, 0.0131, 0.0132, 0.0133, 0.0134, 0.0135, 0.0136,\n",
       "        0.0137, 0.0137, 0.0138, 0.0139, 0.0140, 0.0141, 0.0142, 0.0143, 0.0144,\n",
       "        0.0145, 0.0146, 0.0147, 0.0148, 0.0149, 0.0150, 0.0151, 0.0152, 0.0154,\n",
       "        0.0155, 0.0156, 0.0157, 0.0158, 0.0159, 0.0160, 0.0161, 0.0162, 0.0163,\n",
       "        0.0165, 0.0166, 0.0167, 0.0168, 0.0169, 0.0170, 0.0171, 0.0173, 0.0174,\n",
       "        0.0175, 0.0176, 0.0178, 0.0179, 0.0180, 0.0181, 0.0182, 0.0184, 0.0185,\n",
       "        0.0186, 0.0188, 0.0189, 0.0190, 0.0192, 0.0193, 0.0194, 0.0196, 0.0197,\n",
       "        0.0198, 0.0200, 0.0201, 0.0202, 0.0204, 0.0205, 0.0207, 0.0208, 0.0210,\n",
       "        0.0211, 0.0212, 0.0214, 0.0215, 0.0217, 0.0218, 0.0220, 0.0221, 0.0223,\n",
       "        0.0225, 0.0226, 0.0228, 0.0229, 0.0231, 0.0232, 0.0234, 0.0236, 0.0237,\n",
       "        0.0239, 0.0241, 0.0242, 0.0244, 0.0246, 0.0247, 0.0249, 0.0251, 0.0253,\n",
       "        0.0254, 0.0256, 0.0258, 0.0260, 0.0261, 0.0263, 0.0265, 0.0267, 0.0269,\n",
       "        0.0271, 0.0273, 0.0274, 0.0276, 0.0278, 0.0280, 0.0282, 0.0284, 0.0286,\n",
       "        0.0288, 0.0290, 0.0292, 0.0294, 0.0296, 0.0298, 0.0300, 0.0302, 0.0304,\n",
       "        0.0307, 0.0309, 0.0311, 0.0313, 0.0315, 0.0317, 0.0320, 0.0322, 0.0324,\n",
       "        0.0326, 0.0328, 0.0331, 0.0333, 0.0335, 0.0338, 0.0340, 0.0342, 0.0345,\n",
       "        0.0347, 0.0350, 0.0352, 0.0354, 0.0357, 0.0359, 0.0362, 0.0364, 0.0367,\n",
       "        0.0369, 0.0372, 0.0375, 0.0377, 0.0380, 0.0382, 0.0385, 0.0388, 0.0390,\n",
       "        0.0393, 0.0396, 0.0399, 0.0401, 0.0404, 0.0407, 0.0410, 0.0413, 0.0416,\n",
       "        0.0418, 0.0421, 0.0424, 0.0427, 0.0430, 0.0433, 0.0436, 0.0439, 0.0442,\n",
       "        0.0445, 0.0448, 0.0451, 0.0455, 0.0458, 0.0461, 0.0464, 0.0467, 0.0471,\n",
       "        0.0474, 0.0477, 0.0480, 0.0484, 0.0487, 0.0491, 0.0494, 0.0497, 0.0501,\n",
       "        0.0504, 0.0508, 0.0511, 0.0515, 0.0518, 0.0522, 0.0526, 0.0529, 0.0533,\n",
       "        0.0537, 0.0540, 0.0544, 0.0548, 0.0552, 0.0556, 0.0559, 0.0563, 0.0567,\n",
       "        0.0571, 0.0575, 0.0579, 0.0583, 0.0587, 0.0591, 0.0595, 0.0599, 0.0604,\n",
       "        0.0608, 0.0612, 0.0616, 0.0621, 0.0625, 0.0629, 0.0634, 0.0638, 0.0642,\n",
       "        0.0647, 0.0651, 0.0656, 0.0660, 0.0665, 0.0670, 0.0674, 0.0679, 0.0684,\n",
       "        0.0688, 0.0693, 0.0698, 0.0703, 0.0708, 0.0713, 0.0718, 0.0723, 0.0728,\n",
       "        0.0733, 0.0738, 0.0743, 0.0748, 0.0753, 0.0758, 0.0764, 0.0769, 0.0774,\n",
       "        0.0780, 0.0785, 0.0790, 0.0796, 0.0802, 0.0807, 0.0813, 0.0818, 0.0824,\n",
       "        0.0830, 0.0835, 0.0841, 0.0847, 0.0853, 0.0859, 0.0865, 0.0871, 0.0877,\n",
       "        0.0883, 0.0889, 0.0895, 0.0901, 0.0908, 0.0914, 0.0920, 0.0927, 0.0933,\n",
       "        0.0940, 0.0946, 0.0953, 0.0959, 0.0966, 0.0973, 0.0979, 0.0986, 0.0993,\n",
       "        0.1000, 0.1007, 0.1014, 0.1021, 0.1028, 0.1035, 0.1042, 0.1050, 0.1057,\n",
       "        0.1064, 0.1072, 0.1079, 0.1087, 0.1094, 0.1102, 0.1109, 0.1117, 0.1125,\n",
       "        0.1133, 0.1140, 0.1148, 0.1156, 0.1164, 0.1172, 0.1181, 0.1189, 0.1197,\n",
       "        0.1205, 0.1214, 0.1222, 0.1231, 0.1239, 0.1248, 0.1256, 0.1265, 0.1274,\n",
       "        0.1283, 0.1292, 0.1301, 0.1310, 0.1319, 0.1328, 0.1337, 0.1346, 0.1356,\n",
       "        0.1365, 0.1374, 0.1384, 0.1394, 0.1403, 0.1413, 0.1423, 0.1433, 0.1443,\n",
       "        0.1453, 0.1463, 0.1473, 0.1483, 0.1493, 0.1504, 0.1514, 0.1525, 0.1535,\n",
       "        0.1546, 0.1557, 0.1567, 0.1578, 0.1589, 0.1600, 0.1611, 0.1623, 0.1634,\n",
       "        0.1645, 0.1657, 0.1668, 0.1680, 0.1691, 0.1703, 0.1715, 0.1727, 0.1739,\n",
       "        0.1751, 0.1763, 0.1775, 0.1788, 0.1800, 0.1812, 0.1825, 0.1838, 0.1850,\n",
       "        0.1863, 0.1876, 0.1889, 0.1902, 0.1916, 0.1929, 0.1942, 0.1956, 0.1969,\n",
       "        0.1983, 0.1997, 0.2010, 0.2024, 0.2038, 0.2053, 0.2067, 0.2081, 0.2096,\n",
       "        0.2110, 0.2125, 0.2140, 0.2154, 0.2169, 0.2184, 0.2200, 0.2215, 0.2230,\n",
       "        0.2246, 0.2261, 0.2277, 0.2293, 0.2309, 0.2325, 0.2341, 0.2357, 0.2373,\n",
       "        0.2390, 0.2406, 0.2423, 0.2440, 0.2457, 0.2474, 0.2491, 0.2508, 0.2526,\n",
       "        0.2543, 0.2561, 0.2579, 0.2597, 0.2615, 0.2633, 0.2651, 0.2669, 0.2688,\n",
       "        0.2707, 0.2725, 0.2744, 0.2763, 0.2783, 0.2802, 0.2821, 0.2841, 0.2861,\n",
       "        0.2880, 0.2900, 0.2921, 0.2941, 0.2961, 0.2982, 0.3002, 0.3023, 0.3044,\n",
       "        0.3065, 0.3087, 0.3108, 0.3130, 0.3151, 0.3173, 0.3195, 0.3217, 0.3240,\n",
       "        0.3262, 0.3285, 0.3308, 0.3331, 0.3354, 0.3377, 0.3400, 0.3424, 0.3448,\n",
       "        0.3472, 0.3496, 0.3520, 0.3544, 0.3569, 0.3594, 0.3619, 0.3644, 0.3669,\n",
       "        0.3695, 0.3720, 0.3746, 0.3772, 0.3798, 0.3825, 0.3851, 0.3878, 0.3905,\n",
       "        0.3932, 0.3959, 0.3987, 0.4014, 0.4042, 0.4070, 0.4098, 0.4127, 0.4155,\n",
       "        0.4184, 0.4213, 0.4243, 0.4272, 0.4302, 0.4331, 0.4362, 0.4392, 0.4422,\n",
       "        0.4453, 0.4484, 0.4515, 0.4546, 0.4578, 0.4610, 0.4642, 0.4674, 0.4706,\n",
       "        0.4739, 0.4772, 0.4805, 0.4838, 0.4872, 0.4906, 0.4940, 0.4974, 0.5008,\n",
       "        0.5043, 0.5078, 0.5113, 0.5149, 0.5185, 0.5221, 0.5257, 0.5293, 0.5330,\n",
       "        0.5367, 0.5404, 0.5442, 0.5479, 0.5517, 0.5556, 0.5594, 0.5633, 0.5672,\n",
       "        0.5712, 0.5751, 0.5791, 0.5831, 0.5872, 0.5913, 0.5954, 0.5995, 0.6036,\n",
       "        0.6078, 0.6120, 0.6163, 0.6206, 0.6249, 0.6292, 0.6336, 0.6380, 0.6424,\n",
       "        0.6469, 0.6513, 0.6559, 0.6604, 0.6650, 0.6696, 0.6743, 0.6789, 0.6837,\n",
       "        0.6884, 0.6932, 0.6980, 0.7028, 0.7077, 0.7126, 0.7176, 0.7225, 0.7275,\n",
       "        0.7326, 0.7377, 0.7428, 0.7480, 0.7531, 0.7584, 0.7636, 0.7689, 0.7743,\n",
       "        0.7796, 0.7850, 0.7905, 0.7960, 0.8015, 0.8071, 0.8127, 0.8183, 0.8240,\n",
       "        0.8297, 0.8355, 0.8412, 0.8471, 0.8530, 0.8589, 0.8648, 0.8708, 0.8769,\n",
       "        0.8830, 0.8891, 0.8953, 0.9015, 0.9077, 0.9140, 0.9204, 0.9268, 0.9332,\n",
       "        0.9397, 0.9462, 0.9528, 0.9594, 0.9660, 0.9727, 0.9795, 0.9863, 0.9931,\n",
       "        1.0000])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random batches and only feed these batches forward and backward through the model\n",
    "\n",
    "lr_i = [] # learning rate at iteration i\n",
    "loss_i = [] # loss at iteration i\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    # construct minibatch\n",
    "    ix = torch.randint(0, X.shape[0], (32,)) # Select 32 random indices from our dataset\n",
    "\n",
    "    X_batch = X[ix]\n",
    "    Y_batch = Y[ix]\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[X_batch] # using minibatches, we are back to [32, 3, 2]\n",
    "    h = torch.tanh(emb.view(-1, 6) @W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y_batch) # even better and more efficient than the above\n",
    "\n",
    "    # backward pass / backpropagation\n",
    "    for p in parameters:\n",
    "        p.grad = None # don't forget to .zero_grad() !!!\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    learning_rate = lrs[i]\n",
    "    for p in parameters:\n",
    "        p.data += -learning_rate * p.grad \n",
    "\n",
    "    # track stats\n",
    "    lr_i.append(lre[i])\n",
    "    loss_i.append(loss.item())\n",
    "    \n",
    "    # print(loss.item()) # NOTE: In this case, this is only the loss for the current batch!!! Not the global loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x168012090>]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABzoklEQVR4nO3dd3gU5doG8Hs2ZVNIIUAavSNVepOmgqAiitilWI/HdhQ9KlY8eozlWD4FRT0KdtQDCooFkC6hKU16CYSSEFoa6dn5/gi7mZmduiXZTe7fdXGZnZ2Znayb3Wef93mfVxBFUQQRERFRALPV9gUQERERGWHAQkRERAGPAQsREREFPAYsREREFPAYsBAREVHAY8BCREREAY8BCxEREQU8BixEREQU8EJr+wJ8xeFw4Pjx44iJiYEgCLV9OURERGSCKIooKChAamoqbDbtPEqdCViOHz+O5s2b1/ZlEBERkQeOHDmCZs2aad5fZwKWmJgYAFW/cGxsbC1fDREREZmRn5+P5s2buz7HtdSZgMU5DBQbG8uAhYiIKMgYlXOw6JaIiIgCHgMWIiIiCngMWIiIiCjgMWAhIiKigMeAhYiIiAIeAxYiIiIKeAxYiIiIKOAxYCEiIqKAx4CFiIiIAh4DFiIiIgp4DFiIiIgo4DFgISIiooDHgMWibzYewdoDp2r7MoiIiOqVOrNac03YeiQXj83bBgA49PIVtXw1RERE9QczLBYcPVtc25dARERULzFgISIiooDHgMUCQajtKyAiIqqfGLAQERFRwGPAQkRERAGPAQsREREFPAYsREREFPAYsFjAmlsiIqLawYCFiIiIAh4DFgs4rZmIiKh2MGDxkCiKtX0JRERE9QYDFg8xXiEiIqo5DFg8xHiFiIio5jBg8ZCDKRYiIqIaw4DFkuqqWwYsRERENYcBi4cYrxAREdUcBiwWSKc1M8NCRERUcxiwWCCNURyMV4iIiGqMpYAlLS0Nffv2RUxMDBITE3H11Vdjz549sn1EUcT06dORmpqKyMhIDB8+HDt27DA897x589C5c2fY7XZ07twZ3333nbXfpIaxDwsREVHNsRSwrFy5Evfddx/WrVuHJUuWoKKiAqNGjcK5c+dc+7z66qt44403MGPGDGzcuBHJyckYOXIkCgoKNM+bnp6OG264ARMnTsTWrVsxceJEXH/99Vi/fr3nv5kfyIeEau86iIiI6htB9CJVcPLkSSQmJmLlypUYOnQoRFFEamoqHnroITz++OMAgNLSUiQlJeGVV17B3/72N9Xz3HDDDcjPz8fPP//s2jZ69Gg0bNgQX331lalryc/PR1xcHPLy8hAbG+vpr6Tr1x3Z+NtnfwAAtjw7EvFR4X55HCIiovrC7Oe3VzUseXl5AICEhAQAQEZGBrKzszFq1CjXPna7HcOGDcPatWs1z5Oeni47BgAuu+wy3WNKS0uRn58v++dv0qWEmGEhIiKqOR4HLKIoYurUqbjooovQtWtXAEB2djYAICkpSbZvUlKS6z412dnZlo9JS0tDXFyc61/z5s09/VU8wllCRERENcfjgOX+++/Htm3bVIdsBMWyxqIoum3z9php06YhLy/P9e/IkSMWrt4z0hCFAQsREVHNCfXkoAceeAALFy7EqlWr0KxZM9f25ORkAFUZk5SUFNf2nJwctwyKVHJysls2xegYu90Ou93uyeV7TFbuw3iFiIioxljKsIiiiPvvvx/z58/HsmXL0Lp1a9n9rVu3RnJyMpYsWeLaVlZWhpUrV2LQoEGa5x04cKDsGABYvHix7jG1gX1YiIiIaoelDMt9992HL7/8EgsWLEBMTIwrKxIXF4fIyEgIgoCHHnoIL730Etq3b4/27dvjpZdeQlRUFG6++WbXeSZNmoSmTZsiLS0NAPCPf/wDQ4cOxSuvvIJx48ZhwYIFWLp0KdasWePDX9V7DlnAwoiFiIioplgKWN577z0AwPDhw2XbZ8+ejSlTpgAAHnvsMRQXF+Pee+/F2bNn0b9/fyxevBgxMTGu/TMzM2GzVSd3Bg0ahLlz5+Lpp5/GM888g7Zt2+Lrr79G//79Pfy1/EMapDBgISIiqjle9WEJJDXRh2Xh1uN48KvNAIDVj41A84QovzwOERFRfVEjfVjqG9EPGRYHi2GIiIgMMWCxQDZJyAdxxv8t3YfeLy5B5uki709GRERUhzFgscDXNSxvLt2Ls0XlePXX3V6fi4iIqC5jwGIBpzUTERHVDgYsFkizKnWkVpmIiCgoMGCxwF8ZFoY+RERE+hiwWCDCT31YGLEQERHpYsBigcPHs4SIiIjIHAYsFoh+as0vMsVCRESkiwGLBfKi21q8ECIionqGAYsF0hiFawkRERHVHAYsFvijNX/VeX12KiIiojqJAYsF0nV/fDqtmQELERGRLgYsFog6t4iIiMh/GLBY4PBb4zgGP0RERHoYsFggq2HxYcRiZkiouKwS320+irPnynz2uERERMGCAYsFtbn44b9+3ImHv96KiR+vr9kHJiIiCgAMWCyQDt3U9OKHP249DgD461h+jT4uERFRIGDAYoGsNb8Pz8sKFiIiIn0MWCzwV2t+qay8Ylz25ip8vu6w/A7BLw9HREQUFBiwWOAQ/d+HJe2n3dhzogBPf/+X7x6AiIgoyDFgscBfnW6lg0KFpRWqezDBQkRE9RkDFgukMYq/im4rHLVX2EtERBSoGLBYIGsc5/DdeaVxSaXkxC/8uMv1syAwx0JERPUXAxYLZNOaFfflFpVhV5b+lONF27LwyDdbUVpRqThvtYrK6lsf/57h6aUSERHVKaG1fQHBxKEzS2hA2m8oKXfgxwcuQtemcarH3/flnwCAC1JicOeQNhqPoT4MxAQLERHVZ8ywWCFq15eUlFcN5aw9cMrwNCcLSzXvq9CYfsR4hYiI6jMGLBaYWfwwPMT4KVUmUcysUcQaFiIiqs8YsFjgMDGtOTw0xPg8Ok1ctDIsRERE9RkDFgukoYR8xlD1jfBQExkWnduVHBIiIiJyw4DFAodGDUtxefWsH1MBi9uQUPXPWgELERFRfcaAxQpZ47jqn2UBS4hxLkSvS65mhoUpFiIiqscYsFggDTQqHSIyTp2DwyGiuKw6YPG2OW2l5gkYsRARUf1lOWBZtWoVxo4di9TUVAiCgO+//152vyAIqv9ee+01zXPOmTNH9ZiSkhLLv5A/SWOJz9cfxoj/rMAT87fJMizOollRFLHzeD6KytzXBlJmWLQaxxEREVEVywHLuXPn0KNHD8yYMUP1/qysLNm/jz/+GIIg4Nprr9U9b2xsrNuxERERVi/Pr6SjNZszcwEA32w6iiJJhsUZjPy2KweXv70aV8/8XeU82kEJG8cRERG5s9zpdsyYMRgzZozm/cnJybLbCxYswIgRI9CmjXpnVydBENyODTRawYR0SMhZg/Ld5mMAgL0nCt321+vDwmnNRERE7vxaw3LixAksWrQId9xxh+G+hYWFaNmyJZo1a4Yrr7wSmzdv1t2/tLQU+fn5sn+1paTcPWDRo7eL2WnNmw6dwSdrD3FFZyIiqhf8GrB88skniImJwfjx43X369SpE+bMmYOFCxfiq6++QkREBAYPHox9+/ZpHpOWloa4uDjXv+bNm/v68t1oZVhKK6pXWHYFHLpDODqN4yrNLQM9YVY6nlu4A8t255jan4iIKJj5NWD5+OOPccsttxjWogwYMAC33norevTogSFDhuCbb75Bhw4d8M4772geM23aNOTl5bn+HTlyxNeX70YrmVHhkAQs53fSi1cciphEel6t7ItWDUvGqXM6j0RERFQ3+G215tWrV2PPnj34+uuvLR9rs9nQt29f3QyL3W6H3W735hIt08qwSIdxnF1v9db+EfUyLMpohoiIiPyXYfnoo4/Qu3dv9OjRw/Kxoihiy5YtSElJ8cOVeU4rzCivlBfNiqKIvOJyzfPo1bBoxSsC+7AQEVE9ZjnDUlhYiP3797tuZ2RkYMuWLUhISECLFi0AAPn5+fj222/x+uuvq55j0qRJaNq0KdLS0gAAzz//PAYMGID27dsjPz8fb7/9NrZs2YKZM2d68jv5jVaBq7TupNIh4unv/8KqvSc1z+Peh0Ua8BhnWG76YJ3hPkRERHWJ5YBl06ZNGDFihOv21KlTAQCTJ0/GnDlzAABz586FKIq46aabVM+RmZkJm606uZObm4u7774b2dnZiIuLQ8+ePbFq1Sr069fP6uX5lVYNS7l0SEgU8cX6TNn9U2ZvQAO75KnWy7CYqGFJP3ja6FKJiIjqFMsBy/Dhww2n0t599924++67Ne9fsWKF7Pabb76JN9980+ql1DitGpYdx/JcP6v1UVmxR55tUe7x+/7TuPvTTZh1a2+vr5GIiKgu8lvRbV1x+PQ53DZ7I27u30Iz+zF3Y/UMJYepPizu+yzeeQLrM85oHqNVwTJr5UEAwJ1D9BvzERERBTMufmhg0scbcPDUOby4aJduS30nM21UtE6TnV9s8eqAU4WleHHRLtU1i4iIiOoKBiw6HA4Rh08XuW6baSqrvdqy5Lwa+5zIL3XbtvHQGWSeLtKdJg0ApeXmp0NPX7gDd8zZaCobREREFAgYsOiw2QS8PL6b67ZzfSA9lSZm+WjFNGeLyty2XTcrHUNfW254znKTHXIBYM7aQ/htdw62Hs01fQwREVFtYsBiICU+0tL+poaEIKoWLldUep7xKPcgW8KFFomIKFgwYDEQarPWsG3WygOG+zgc6lkWMwsnaimvsN4hl+smEhFRsGDAYiDEYsBihghRtY5Fr2mcQQkL/rvmoGzVaFPXwYiFiIiCBAMWA/4IWByieu84vSGho2f1ZxB9vi4Tn6Yf8u7CiIiIAhQDFgN+ybCI6sMx5V7UsADArqwCE49d/RjMrxARUbBgwGLAag2LGaIoYvuxXLftZmYY6WmREGXisdV/1vPJ2kMY+84anC50n3ZNRERUExiwGPBHhuXwmSJc+16623ZvZ+00bhBuuI+Z5ndKzy3cge3H8jBj+X7jnYmIiPyAAYsBfwQs+3MKVbd7M0sI0B7iWbPvFFbsyQEgX1xRtDgoVGKhOR0REZEvMWAx4I8hIS3e1rCoBTylFZW49aP1mDJ7I/JLyuVBisWHc85UKimvxK6sfM4yIiKiGsOAxUCIreaeIm9rWNQSNKWS/iyFJRVe9V5xxm43fbgOY/5vNX7YluX5yYiIiCxgwGKgJjMs3tawqK0NJN0mQl7DYvXRhPNrRm/OzAUAfLvpiM7eREREvsOAxYCtBgOWkwXezcJRK6iVDjNVVooezRJyqsGngoiISIYBi4GazLDszjbuo6JHbaVoaffcskqHR7OEnJQrRhutIE1EROQrDFgM+GOWkL+oxSLS7rllFQ6vZgkpBc8zQ0REwY4BiwGzGZZFD16EtPHd/Hw1+tRqWMor5RkWeDUkpMywWDueiIjIUwxYDJitYQm12Wq9xkN9SKh6W7liSMhy0a3i91MGMERERP7CgMWA2QxLiK32azrUJhnJMiwVioBFFLFgyzHsO1Hgul+veZ3yqWC4QkRENYUBiwGzNSwhNlutZxzUhoSUNSzSPZbsPIF/zN2CkW+uQmlFJfq9tBRj/m+V5vndi269vmQXh0PE7ux8r7v9EhFR3cSAxUCoycZxoTah1oeE1Kc1a88S2no01/Xz3uxC5BaVY++JQjgcItIPnEZBSbnsXO6/nvlfWBRFvL/yAJbtPqF6/9vL9mH0W6vxzIK/TJ+TiIjqDwYsBswGISE2odYzLGo1LOXKDIuJotvP1x/GTR+uw00frpNt9ybDsj7jDNJ+3o3b52xSvf+tpfsAAF+uzzR/UiIiqjcYsBjQq0t5+NIOrp9DbUKtz5pRndbskNewaAUp0inOczdUdbD961i+bB/3olvz15aVV2x+ZyIiIgUGLF6Itoe4fg6IDItBDYtylpDW5ZZVqq9p5F50a2VIyPSuREREbhiweEE6gyg0EIpuLdawSEmDjzLJgonSFZmVAUptZ5SIiKj+CK3tCwhmoSHV8V5ISO0X3UpjkaNni7Dx0BlZTYjZISFpwCLN2igDFCsBCzMsRETkDQYsXpBnWIRa78MiDS6Gv7bCbfXnskrtgEW5n+ucsiEkRYbFypCQ6T2JiIjccUjIC2HSDIsfpzUPbtfI1H7S4R5lsAK4N47TopVhefu3fbIhJq34rKLSgevfT8cz33OKMhER+QYDFi+EhlR/YocI8qLbRtHhPnucyDBzibBKhygLNpSURbdapOfYo1hB+sdtx10/a2WU0g+exoaMM/hs3WHXNpFjQkRE5AUGLF6QNpWz2QRIe8w9O7YzYiN8M+JmDzX3v2nuxiPo/eIS5BWVq95fUSlfn1lrSEc6JHTNu2tl950rrZQcr046M6kmnD1Xpvk7ExFR3cCAxYRLL0hU3d4usYHstjTjYBN8V9MizeQYKSipwK87s1XvK68UZZkOafhitiO+9FeyVHRrfldLSsor0fOFJejxr8Vs609EVIdZDlhWrVqFsWPHIjU1FYIg4Pvvv5fdP2XKFAjnP6yd/wYMGGB43nnz5qFz586w2+3o3LkzvvvuO6uX5jcfTuqDObf1ddueEB2Olf8cjvVPXgJAvnpxVcDim8eX1sqYoTX8UuFwyAITaWM4sx/2yt9R9fHVwhM/xRInC0pdP5dWVOrsSUREwcxywHLu3Dn06NEDM2bM0Nxn9OjRyMrKcv376aefdM+Znp6OG264ARMnTsTWrVsxceJEXH/99Vi/fr3Vy/MLQRAQERbitj3EJqBlo2gkxUYAkDdWC7Fpf6BbFW5ySMhJo+/b+QyL+n0VWgcpHDtb3bGWbViIiKimWC6yGDNmDMaMGaO7j91uR3JysulzvvXWWxg5ciSmTZsGAJg2bRpWrlyJt956C1999ZXVS/QLtVWbldukAYoguM8aGtimEf46noeCkgpLjx1uMcOiVVhboVN0W26y7mTG8v3VNywNCfknxcLmdURE9YNfalhWrFiBxMREdOjQAXfddRdycnJ0909PT8eoUaNk2y677DKsXbtW4wigtLQU+fn5sn/+pDZlOVSxUfrhGSIIUH6if3X3ANw2qJXlxw6zUMMC6A0JiToBi7kMi1QgtOY3s5gjEREFP58HLGPGjMEXX3yBZcuW4fXXX8fGjRtx8cUXo7S0VPOY7OxsJCUlybYlJSUhO1u9eBQA0tLSEBcX5/rXvHlzn/0OatQKaPUyLDab+rf/UIvZEsB6DYtWPUq5TuM4rfWD9GhlN9QeQ5Td75/IwsyUbSIiCk4+73R7ww03uH7u2rUr+vTpg5YtW2LRokUYP3685nHKgEAURd1ZNtOmTcPUqVNdt/Pz8/0atKjVoxgNCaldvdrQkpFIlfoZPVrBR4VODYte/xYtWr+KUdzgEAGLSSNN0v8tDFeIiOouv7fmT0lJQcuWLbFv3z7NfZKTk92yKTk5OW5ZFym73Q673e6z6zQSohawCMqARX6fWrwVGxlm+bFjLPZzKSpTny1T4XDgXz/uUL3PX0NCaoGnQxQR4qOSXdmQkPVfgYiIgoTf+7CcPn0aR44cQUpKiuY+AwcOxJIlS2TbFi9ejEGDBvn78kxTCz5sbjUsimnNKh/KbRpHW37smAhrQU5xuXrAUl4pYuOhsxr3+W5ISMo5OiUNLPw1dMMhISKiustyhqWwsBD791fPFMnIyMCWLVuQkJCAhIQETJ8+Hddeey1SUlJw6NAhPPnkk2jcuDGuueYa1zGTJk1C06ZNkZaWBgD4xz/+gaFDh+KVV17BuHHjsGDBAixduhRr1qzxwa/oG2amKEvjF5tNfciktQcBSwOLGZZinQyLlsfnbbf0GIBODYvkZ4coorJClM0S8mVcwSEhIqL6wXKGZdOmTejZsyd69uwJAJg6dSp69uyJZ599FiEhIdi+fTvGjRuHDh06YPLkyejQoQPS09MRExPjOkdmZiaysrJctwcNGoS5c+di9uzZ6N69O+bMmYOvv/4a/fv398Gv6Btmak/cG8e5H5McG4Hk831bzLI6JKQVsJidumyeAFEU8fT32/HOb+pDfukHTqPD0z/jw1UHXduMApYZy/Zh2GvLcapQu1Bb7VyP/W+bqasmIqLgYznDMnz4cN1ZHr/++qvhOVasWOG2bcKECZgwYYLVy6kxZmplpQFLiE29hsVmE/DbI8Pw2q97MGftIVOPHWO3NiRUoiigtYfaUFrhMN0cziybAOw5UYDP12UCAB64pL3bPo98uxUAcOh0kWub0dDNfxbvBQDMXL4fz43toruv9FRLd50wdd1ERBR8uJaQSWbWBZLuYhO0h0yi7aF49srOuGtIa1OPHW23NktIGZg4u/RW+HitHUFwz+YUlJTjRH6J67ZacGu21sTMzCV/NaQjIqLA4vdZQnWFR0NCOjNhbDYBT13RGcv3nMT+nELd80bbrf1vUhbQOld79vWQkPL3czhEdJu+WLbtVGGZ23Fmr8JMfMX1DomI6gdmWEwyMwnXJnk2bYKAvq0SfPLYUeHWMizKwMQeVnVhvh4SUmaQKk1mTsxOPzbTYI4zg4iI6gcGLD6kzLA8O7az4TFmAqGocO8yLBGh/hkSUs6cMrvis9kgw8x+jFeIiOoHDgn5kHJac5yJJnF6pTFtm0TjziFtLHfHdRsSCrOpbvc13wcsxvv4q80/EREFFmZYfEjZOM5bdw9tg5v6tTDxuPLbbkNCzgyLr2tYBPnvbHpIyOT5zQQ2/q5hKdFowkdERDWLAYsPKac11xTlqtHK2TUR5zMsnixwqOfgyXOyrE2lyYDIbIbFzG7+nCX08/YsdHrmF3xicvo5ERH5DwMWH7IJ6j/7wsL7B+M5jZoY5VBMaYU8K+DMsOQXl/v0mlbuPYnJH29w3TY75GR2FOe7zccMm8fpNO/12r1f/gkAeG6h+vpLRERUcxiwmGRmhEdZdOuJx0d3cv3cLrG6O3D3ZvG4bbB63xblsEhJufq0Zl8X3QLyhRbNZnCszOy5/v10n52LiIiCF4tuPXD1hakY1SXZbbu8cZy5gEXZy6Rvq4ZY9OBFOHSqCL1bNvTo+pQZFmfjOH8z2+dl/cEzuPiCRMSaWNTx4Mlzuvf7M15hLEREFDgYsJjUrGEU2jaJRrQ9FG/ecKFq51u1DEuLhChknilCQnS4qccRBAFdUuPQJTXO42vVyrD4m9khoYe+3oJ2iQ2wdOowU/tXOkTM/j0DfVsloEfzeNl97HRLRFQ/MGAxKcQmYPHDwyBAu02/LGA5HyN8ens/vLNsP/4+vI3qMcpTeTKS1K1pHLYfy3PdVs5sqamAxUwrfSej7r5S8/44ihcX7QIAHHr5Ctl9ylEuURRNLaNARETBhTUsFoTYBNh0qmltKkNCrRpH4/Xre8jqUfR4UvvStkk01j95CX59aCgA91qVmhoS8sUsJLVff3d2geb+yhqWmmjVn3m6CG//tg95Rb4tYiYiIm3MsPiQ4INpzZ4cVuEQkRQboZnhqLEhIQsZFi0C3Pu0hOhcvrLOxCGKCDHVP9hz42auwdmicuzKysd7t/b262MREVEVZlh8SBpseDoqYTbDIq3lKD0fKIRrBCb2oMqwuP/+ITbtl6my021NFMqePZ9ZWZ9xxv8PRkREABiw+JT0w1ZvpWb9c5jbT9oszhmwhGmkIgKt6FaP2q+vl2FRDgFxmjMRUd3EgCXAmA10pJmFc6UVAIDQEPVja6rrblmF98GCWsAmzTqlHzgtKyqujQyL1mMTEZH/MGDxE4+HhEz+H5FmFs6eKwMAhGukImosYPHTkJA0YLnpw3W4/3wHWkBlltD5ChhRFA275BIRUfBgwOJDnnzjVn5Am61hkT7SmaKqgEVrSMgXCzGa4auiWyVlwLV0V47rZ+Vz7gxg0n7ejT4vLsXCrce9viYiIqp9DFh8SPrBGmK6062c2WSI9IM693wRaIhNUD1euTiivzzy7Vavz6H2tOlliJQhorOG5YNVBwEA//php9fXREREtY/Tmn0oPioct/RvAYcINDTZ2bZloyjszMp33Tbb9EwrmRMZFoJzZfLGcXq9Y4KBVobI4RCx7uBp2Tbl81KqaKJHRETBiQGLj/37mm6W9v/XuK7Yl1Po6vxqNrQQIWJM12T8/Fc2hnZo4toeGe4esART93q1QExr5s/Hv2fgnWX7FcfL9y1mwEJEVCdwSKiWNYmx4+0be7pum603cTiA167rgVev7Y63b7zQtV2tq21lgM5mcai0pVW70gqNRRW/XJ/pfk5RvkSAP1aodgrMZ5WIqG5iwBIApDODrBTdNrCH4vq+zREfVT38FKkWsNREv3oPdH9+MZbtPiHfqHKpFQ71Yl61QGzK7A248F+LfXF5REQUQBiwBABpkGJ2Qo/WjKSsvBK3bYEasBSWVuD2OZtk29SGf9SyJFO/3oLDp4vctm87moci5ZAYEREFPQYsAcCzgEV9e1FZhds2XwQsNTXTSH1IyD3DMn/zMY/OX1JeiQMnza8UTUREgYEBSwBQW+XZiKhRQaEWm/iiXX3jBnavz6EmTNGdVy1zVK5Rw+KJq2aswSWvr8Ta/ad8dk4iIvI/BiwBQBqkGAUsV3RPAQDcM6yt6fP7ovDUX73nlN15VTMsGjUsnth7oiq78v0WeYZGrQCYiIgCBwOWACAPWPT3ffvGnlj1zxEY36uZ6fOrDQklx0aYPh4wP93aqjDFwoxqySB/1OBI12zan1OIni8swczl+3WOcBegk6+IiOokBiwBQDpLyKhxXIhNQItGUZbOr5Y9mH/vIEvn8JewEJthdsOXQ0JO0qf5Xz/uRF5xOV77dY/PH4eIiHyDAUsA8KToVkuM3b0XYI/m8bLbcZFhaBLjn5oUq04XlmLoa8t191EruvWlIG8ETERULzBgCQCCB0W3Wj69o5/s9oeT+mBI+8aybb89Mszy45hdMsAqhwgcPVusu8+y3Tm693vCl885ERH5HwOWAOPtt/2eLRq6fm7ZKAojOydBEARce77mZcbNPdG4gT2osgr5Je5TtX2ppp+LkwWl+OPw2Zp9UCKiIGc5YFm1ahXGjh2L1NRUCIKA77//3nVfeXk5Hn/8cXTr1g3R0dFITU3FpEmTcPz4cd1zzpkzB4IguP0rKXFvglYXSQtAfZnJkBaFvjahO35/4mJc2T3V548TnMzPzPK1/i8txbXvrXVbuJGIiLRZDljOnTuHHj16YMaMGW73FRUV4c8//8QzzzyDP//8E/Pnz8fevXtx1VVXGZ43NjYWWVlZsn8REdZmstQF/vrstNkENI2P9Pj4uhbfSH8fT383rW7DRpw1xmv2sRcMEZFZlldrHjNmDMaMGaN6X1xcHJYsWSLb9s4776Bfv37IzMxEixYtNM8rCAKSk5OtXk6d48upslrN5UjOVxmWNftOoVnDSLRqHO2T8xERUTW/17Dk5eVBEATEx8fr7ldYWIiWLVuiWbNmuPLKK7F582bd/UtLS5Gfny/7F6xkn5e+DFgYrwBQz4RIn3KbD4pYthzJxa0frcfw/6zw+lxEROTOrwFLSUkJnnjiCdx8882IjY3V3K9Tp06YM2cOFi5ciK+++goREREYPHgw9u3bp3lMWloa4uLiXP+aN2/uj1+hRoRJur3afPh/hAFLFbU2L76eJbTtaK7X5yAiIm2Wh4TMKi8vx4033giHw4F3331Xd98BAwZgwIABrtuDBw9Gr1698M477+Dtt99WPWbatGmYOnWq63Z+fn7QBi0J0eG4e2gbCAIQExFW25ejKphrWCocDoTYQjTvt5Jg0eoJ40lwyCE7IiLz/BKwlJeX4/rrr0dGRgaWLVumm11RY7PZ0LdvX90Mi91uh90eGM3PfOHJyy+o7UvQJfitOb//HTlTjHaJDWTbBA9mCW09kotxM3/36bUREZE5Ph8ScgYr+/btw9KlS9GoUSPL5xBFEVu2bEFKSoqvL69e8XQWixorGRZlcFDbLn1jpep2URSRV1xu+ndTBivMjxAR1RzLGZbCwkLs31+9SFxGRga2bNmChIQEpKamYsKECfjzzz/x448/orKyEtnZ2QCAhIQEhIeHAwAmTZqEpk2bIi0tDQDw/PPPY8CAAWjfvj3y8/Px9ttvY8uWLZg5c6Yvfsd6y5cfqFZin2YNI7E/p9CHj66uVaMoHDpd5NGxggC8s2w/3liyFwnR4T6+MiIi8jXLAcumTZswYsQI121nHcnkyZMxffp0LFy4EABw4YUXyo5bvnw5hg8fDgDIzMyETVJdmpubi7vvvhvZ2dmIi4tDz549sWrVKvTrJ28zT9ZEq6wrpGZI+8ZY7cOeICE1VPAiLVa2SgDwxpK9AIAz58q8vhZPslksiiYiMs9ywDJ8+HDdN2czb9wrVqyQ3X7zzTfx5ptvWr0U0vDeLb3w+pK9eOemnqb2l9ZwhNgEVKpMq7ESg/himrAZ3gQsZb5YUJEBBxFRjeFaQnXQmG4pWDp1GC5IMVfsLI0vQiQ3YiKq41mtEGTKoFZu22ouw+L54xSWVvrwSoiIyN8YsJBsXaFQScASK5lirbX20JOXX4AHL2kv2xZSQxkWtf4qWr7akInThaWu21rTkz3lSbKFCRoiIvP81oeFgoc0vNDKsGgJsQmyIAdQHxL6+R9DEBZi05yx4wm1oSst0+Zvx9yNR1y3y30csBARkX8xYCFZ9kRaFxJroomdTXDPqCgDGACmh6escFisWt16JNf1c3ml+rHOGixlRsmXU8SJiMg6DgkRBAG4qkcqhrRvLOuhEhupHs+O79VUcqzgFrD4ajFBIxVWxoQUtDIso99ajTs+2eS2/bN1hz1+LCIi8h4DFoIoAm/f1BOf3dFfVjArXSYgJS7C9XNnRbZEWWSrlmHxBytDQkoVGhmWPScKsGx3jltG5dkFO9z29TbnwqQNEZF5DFgI0o9e6eKL0hqW167rgYs7JeKLO/u7DcUoa1Z8Ma35onaNDffxJmApd+jXsFjN3jD4ICLyL9awkIx0jR1pDUvT+Eh8PKUvAOCvY3myY5QZFS/ao7jERRnXz/gjw+LEolwiosDCDAvJSEd3tGYJKT/qlRmVEEHA5d2SvbqOBuHGsbRXGRaDgKSswlrAwgQLEZF/MWAh2XCGTaOGRUo5JKSsYQmx2TDjpl5o2yTa42tqYGJKdaUX4zBGQz5mApbC0gqv+rmIDHOIiExjwEKyj01pskRrlpAyTlAbErLZBLRIiHI79sNJfUxdk5l1kPyaYTEZiMxZe8jjayAiIvMYsJCMdIpy68bqGRLlDBqtotsQm/vLa2TnJNw2uJXhdcSYCFgGtmlkuI8WoxqWdQfPmDrPyr0nPb4GIiIyj0W3JAtApA3TuqTG4YWruyIpxq7YX368ssjWOUR064AWWLrrBPq2aii7//HRndC/dQLu+fxPzWtKjLVr3nf/iHaIjwrDpRckYdH2LM399BhlWB79dqup81htXicL9jgiRERkGgMW0hwSAoCJA1q67a8ciVFmUpxZmuEdE7H80eFIjY+Q3R8RFoLRXVNwU78W+GpDpuo1JcdGqG4HgBaNonB9n+Y4JVkbyCpvms5J/b7/NI6cKTLdCddHD0tEVGPKKhzIKShBs4buw/w1iUNCpFl0q8W46FY+rGQPDVE9z0vXdMX6Jy9RvS8lLlLz8Z3X6E1HXV9OWx7+nxWm95U+d4xdiCgY3PBBOi56ZTnWHzxdq9fBgIVkzAQByg9a5ZCQ2U63giAgSSOTojck5Dy7N/3pfBmwWCn+tTqERERU2zZn5gIAvt50RH9HP2PAQvIAxEQQoBz+UA4JxUWFe31NYTrd55wP501HXat9VnxFVsLC4IWIyDQGLCT74DSVYTEour2+TzOvruebvw3UzZ44u/F6MyRUW7UkzLAQEXmGAQvJmElaKBueSTMsr1zbTbNmxayo8BDZbCUl513K2plg4EmgVFHpwH1f/on/rj7o+wsiIgoSDFhIxlzRrfy2NHDwJuvh5BwOGtJefQFEZzAThPGKRxmWX3ecwKJtWXhx0S4/XBERUXBgwEKyIR4zQYD7as2Sn30QRYSGVJ3j09v7qd7vzAL54rF8xWxtiuiQ7mfu3AUl5R5eFRGR7whmihz9iAELyYZ4zAQBN/drAQC4uFMiACBUErGoNLe1zDnLSGtYyPlHE+LNNCE/Kq8UsfHQGZRWVLrd50mGhb1biIjYOI6g7MNivH/LRtHY8fxliAqvqlUJ8XGGxSgQEVwZFq8fyi9e+3U3PlydgXEXpuL/buwpu88oYCkoKYdNEGRrKXmzyCMRka/U9oKtzLCQjNmAI9oe6sqA2LysYVH2bdGb0lz1GFX/1SvMrU0frs4AACzYctztPmm2RJk5KatwoNv0xejy3K+y3i6c/kxEviaKIp75/i98EkQLuDLDQooaFutBgHRV5iYx2g3ftMRGhuHMuTLXbePGc4EZqJghDT6U2ZacghLXzyXlla4sizerUhMRqdl0+Cw+W3cYADB5UCtTx7CGhWqdNM13ZfcUAEBqnPZaPkqNGtix4alLMPfuAejfOsHy48dGyOPmsFBzGZZAYjZV6tApztVKpDBeISJfKypzr7ELdAxY6rF+raqCi5vOF9ECwOB2jfHzP4Zg8dRhls6VGBOBAW0aeZShSRvf3fXz7YNbIzYiTHd/tccINwhy/O2ln3arbl974JTstkOWYYHmfdK6FQ4JEZGvhUm++QXLewyHhOqxz+7sh8Oni9A+sYFs+wUpsTV6HQPbNsKuf41GZLi5hnPSDMttg1sh83QRGjew1/o6F2pu/nA9Dr18heu2VlBSdZ/kZ8kNDgkRka+FSmoFyyodXjf8rAkMWOoxe2gIOiTF1PZlAIDpYAWQ94p5bmwXAMDRs0UBGbAoafVr+WzdYXyWfsh1W684l4jIW2Eh1W+kZRXBEbBwSIiCjtqQULOGUegYIMGXHtmQkKSJ3DPf/4W9Jwpdt6VZFa4/RES+Ju2fVVuLwVrFgIWCjlaVTISFLE1tkWdOtAMReWDDgIWI/KeskgELkV9o9XoJwMlDbqSByK7sfFRovFHIMyx+vywiqmekMxtLy80FLLXd+ooBCwUdrT+a2v5jMkNat/LXsXw8Nm+b6n4cEiIif5J+EaqzGZZVq1Zh7NixSE1NhSAI+P7772X3i6KI6dOnIzU1FZGRkRg+fDh27NhheN558+ahc+fOsNvt6Ny5M7777jurl0Z10IiOTQBUT8EGtDMsNbEYonFTO3Ul5VU9D5TZkvl/HlPNsjh0GswREXlL+r5SZ2tYzp07hx49emDGjBmq97/66qt44403MGPGDGzcuBHJyckYOXIkCgoKNM+Znp6OG264ARMnTsTWrVsxceJEXH/99Vi/fr3Vy6M65r1be2Pe3wfi7yPaurZphQw1kWCxeRCwrNp7Ep2e+QXvrzygGnyUqrxZzFy+H8VlziCHPVmIyLek7yVq70GByHLAMmbMGLz44osYP368232iKOKtt97CU089hfHjx6Nr16745JNPUFRUhC+//FLznG+99RZGjhyJadOmoVOnTpg2bRouueQSvPXWW1Yvj+qYiLAQ9G6ZALukZ4BWczpPMix/G9bG0v6eJFgmfbwBAJD2827ZzCAnZ/ZF6ptNR/HGkj0AlN1xrT8+EZGS9H1FbWX5QOTTGpaMjAxkZ2dj1KhRrm12ux3Dhg3D2rVrNY9LT0+XHQMAl112me4xpaWlyM/Pl/2juitUFrBo7ORBMNHZYpM86VRAT6hlWEo0vt1syDjjdgyHh4jIF6SzD+vskJCe7OxsAEBSUpJse1JSkus+reOsHpOWloa4uDjXv+bNm3tx5RTopE2OtGtY5LfNJFyiw631TvR2HaO84nK3bWoZFgAor6x6Q3FwxhAR+Zis6LY+BixOypS9KIqGa8xYPWbatGnIy8tz/TtyJPC7nJLnwkxkWJQriZoZIoqy2LvFkxoWqVv+616XpRWwFJdX4sy5Mkhrcv2dYfkz8yzWHTzt18cgotpXL2pY9CQnJwOAW2YkJyfHLYOiPM7qMXa7HbGxsbJ/VHeFyjIs6vso45OYiFB8NLkP7ryoteZ5o+zWMiyezhLSU6LRAyHj1Dn0emEJsvOLff6YahwOEePfXYsbP1iH3KKyGnlMIqod9T7D0rp1ayQnJ2PJkiWubWVlZVi5ciUGDRqkedzAgQNlxwDA4sWLdY+h+kVeO2Ku6DY2IgyXXJCEp6/srHnepFi7pevwx9Tp/BL3YSKpVXurV3zWyrBk55Xgv6sPGp5LT4XkHexskefnIaLAJ30vKdbI8gYay4sfFhYWYv/+/a7bGRkZ2LJlCxISEtCiRQs89NBDeOmll9C+fXu0b98eL730EqKionDzzTe7jpk0aRKaNm2KtLQ0AMA//vEPDB06FK+88grGjRuHBQsWYOnSpVizZo0PfkWqC8I8yLDERuq/vOOjwhBlsYYlxA8ZlpcW7TK9r1YNyw0fpOPw6SJsPZqHd27q6dF1SDtfBkEPPiLygjRgOVdaYeqY2n5fsBywbNq0CSNGjHDdnjp1KgBg8uTJmDNnDh577DEUFxfj3nvvxdmzZ9G/f38sXrwYMTHVC9NlZmbCJvnGPGjQIMydOxdPP/00nnnmGbRt2xZff/01+vfv783vRnVIqIlpzcrtOfmlrp+njemEtJ93y+5v0sCO8BBrSUZ//MHuyynUvV80MUvo8OkiAMCK3Tma56modGB3dgE6p8Sq1uJwAhJR/SH9ey80GbDUNssBy/Dhw3WbVwmCgOnTp2P69Oma+6xYscJt24QJEzBhwgSrl0P1RJjNRIZFcTunoDpg+duwtu4BS4xdVhujJtQmyIZKjIrH/eFcWXW6VjQaata5vOcW7sAX6zPx4CXtMXVkB7f7OWWaqP6Q/r0XlJgLWGr7HYJrCVFQkGZYtD5Xx3RNtnTOhlHhhkW0yoDGyzYsXnOIIhwOUXMF54KSChw9W6R63xfrMwEAb/+2T+Pc1T/X9hsTEfmX9O/dbMBS2xiwUFCQBg6VGhHL9X2ao2FUmOt2+8QGuue0h9oMMybKRnHKqdM1zSGKGDfzd1z+9mrNoGX6QuO1u7TOTUR127sr9uP699NlhbaFpeaK7IOuhoWoNoRJAgetD2qbTcBF7Zvgh63HAQAzbu6le06j4SC1ffxQc2tJXnE5th/LA1A15JUcF6G6jye0nlciqjte/aVqyQ/pRIZgqWFhhoWCgjRwqND5YJVmCVo1jtI9Z5iJgltlfFITK0LrqZT87lrBk3OXVXtP4ob303Ho1DlT52a8QlR/FElq4wp1hoQCacFVBiwUFKS1JnqZAOkfV4hBcGEmYHF7qFrOsDz6v23VN85fy4/bjsv2cQY1kz7egPUZZ/DQ11tMnZtDQkT1h2iyhkW637d/HMVf5zO8tYEBCwUFaa2JboZFMovGqGdKmIkhIeW3i9rOsGw9kuu27f4vN8tuKwOPk+dnSxkVGHORRaL6QzZLSDEkJH3f++u4PEApr6y9rrgMWCjoVJocEjIqqDWTYVF+bhtlbWqSQ+N9Q+v5iQjTXzdJ+rsGUhqYiHxP+l4pHRL67+qDGJi2DDuO5+HT9EO4asbvsuO8XbHeGyy6paCjH7CYP0+oqSEh+QkDKF7RnC2l9fzYQ20oLFW9C4Ayw+LVpRFRgJN+4Skur0RFpQOhITa8eL7z9hVvq3ear83WDsywUNAY0r4xGkWHY1C7Rjp7mf+kDTcxJBTIH9xatTxayRF7qP6fuzTQ4ZAQUd2m/Bs/V2puPSFmWIhM+PT2fqhwiLpDOVYCDOd5WjWKwqHT6s3WlFmM2q5hkdLKpCiv2Tm8YzREJj1Ma7iJiOoG5XeS/JJyxEn6WGmxuJqJTzHDQkFDEATDuhMrtRfOIaFfHhqKVf8cobpPhaLArLY73UppDQl5mh1h0S1R/aF8/zDbiyWkFt8EA+jtl8h7VjIsziGhiLAQtGik3rNFeb7a7nQrpTUkpNyutpdaYCdrzc94hahOU34pMR2w1GKWmQEL1Sl6mYEWCfKgxEzRrVLjBuGm9msaH2n53FZpZ1iMj1XbhxkWovpD+SduOmAxUfvnLwxYqE7R+5ydf+8gPH9VF9dto74kahpGhePbewZi4f2Ddffr1bKh5n1m+r+YoVnDosywqOxWoVKkkimp42HAQlS3Kf/GKyrN/c178r7pKwxYqE7R+6Bt3MCOa3o19fox+rZKQPdm8br76P1RGzW0M0urMNZMsKH25nTbnI2Sc2gf++yCv3D3p5vYq4UoiCnfJ/TaRUjV5sQDzhKiOsXowzpcMgyk3HVwu0b4ff9p/Qcw+beq90ddNS2wKtoIsQmm3yiUXvhxJ06pNFZxy7CoVLHodQsG9IuXP00/DADYnV2AC1JizVwqEQUY5Rces+9DtZlhYcBCdYrRl35pLxJlcPPuzb3x645sLNudg192ZKseb7boVu9vWpphCQvxPGDZcOiM6nbl6coqHBBFURaEGD2m1t1WzkFEgUv5pUSrJk7JxiEhIt8w+puT9iJRft7GRYXh+r7NERPhfRyvl2GR1rCYWR7AKmUgdraoHM8u2CF7Qxr7zhp8vTHT9Dmcth6tXlckgFrSEJFFyve/SpPNl1jDQuQjVopF1YZKAN98EOu1KpBmWMJrIGABgM/WHZZlRI7lFuPxedtdt5XftrSex6tnVq8rEkhTvInImCxD6mHRra9q8DzBgIXqFCsBiycjGtJgZt7fB+nsZ1TDUiXcoF2+J7SGavTqVpT3TZu/Hd9uOqL7OIHURI+IjOktcPr8Dzvx0NzNMMKAhchHrAQhkQarF6uR/qmmxkdo7qf3Ny2NZfwxJKQVs6l9g/ppexYuemUZ/jh8Vrb98Oki/PN/23QfhxkWouAi/UKn1ofl+y3HDc/BxnFEPmImXnnq8gswomMTXNUjVfV+84W1OlOXFffdP6Jd9fllAYvv//jVeqxobb/3iz9x9Gwx7v/S+JuVEmtYiIKL9Aud2SJbJRbdEvmImd4gdw1tg9m39TM1HBOrKMCVfkjr/dlK/6gvSInF34e3lRzn36LbknL1gEVrOwCUV3K1Q6K6TtbNOghn+TFgoTrFFx1apUHJ//4+CDf2bV59H8xFLNLsiwD5uK/0/P6oYfGE3YPrYN84ouAiX36jFi/EQ4HxbknkI774EJUGFB2SYvDytd1V99MbEpJmTQVBEbBI9vNHhgUASsorLe1vD1O/jnOlFZj3x1HkFpW5FfOqBYcbMs7g6Nkit+1EVPukf8LBuPwGG8dRnVKT3xp0h4QEeUZFq1DNXxX3Z4vKLO1vD1UvQH52wQ7M+/MoerdsiAhFUKN8w9t2NBfXv58OADj08hWWHp+I/E+v6DYYMGChOsXf69vIalh0MizK+7QK1fxVv7ZoW5al/ZXBiNOCLccAwG0WEeDe2lttHyIKHKLkb9bTotvaxCEhqlP8neaUxiH67fclxyhyMdJgxl8Lib24aJel/bUyLHoZIOVzHYTvf0T1ijzDEnx/sAxYqE7xxZBQkwZ2zfukNSd605+VQ0JS0puBMjVYKy7Ra8OtDFiCcUycqD4J9qJbDglRneKLD82/DWuLAyfP4fJuKa5tT4zphG82HsEDF7ev3tHkLCE3solGgRGxlFaoT2vWz7D462qIyB+kw0DBuHgpAxaqU3zxJT/aHoqZt/SSbbtnWFvcM6ytbJv0szw2IhT5JRWS+9RnBenZ8uxIfJZ+GK8v2Wv5mr1VqtGjRfo7KSlTysrnft+JAggC0C4xxuvrIyLvBXsSlENCVKfU5LCEtBald8uGsvtsOuM+WgFMfFS4rDi3JoeLSiusTYMG3L+hSZ/74rJKjHxzFS59YxXKNLI3RFSzgn3YlgEL1Sk1+fcoj0m0ZwUp4w692UVa/Vr8TWtISM/352cQOUmf+rzictfPxRZ7whCRfwThKJCMzwOWVq1aQRAEt3/33Xef6v4rVqxQ3X/37t2+vjSqB0RTqwn5hn7jOHPhhvJ6Q2TFujUXslhtNAcAX204Yqq9d6AUFhPVd8HYjl/K5zUsGzduRGVl9ZvfX3/9hZEjR+K6667TPW7Pnj2IjY113W7SpImvL43qAY11//xCb12hgW0bYWTnJCzZeQJ3DWkjP07yszIjZHatIl/zJMMCAOUOB+y2qinRu7LyVfcROSJEFBCCfUjI5wGLMtB4+eWX0bZtWwwbNkz3uMTERMTHx/v6cqieqa3eAtJAIyE6HBc2j8esW3vj2NlitGgUpbmvktaaQ/7mSYYFACoqRdhDgZMFpVigsTS91urRRFSz1BIsNiF4hor8WsNSVlaGzz//HLfffrthertnz55ISUnBJZdcguXLlxueu7S0FPn5+bJ/RDX5h6c17NOzeTyAquBDGawYkQcsNRexePq8OVd5zjxzTnE+yfTJIP9WR1RXqGVY/LWemT/49Uq///575ObmYsqUKZr7pKSk4IMPPsC8efMwf/58dOzYEZdccglWrVqle+60tDTExcW5/jVv3lx3f6ofanaWkOyWxnaV4yT7JsbYFfep/2xkZOckU/vdNriVhbMaK690Pt/yq5XOIGKChcg/yisdWHfwtOkMqVoGOjyIAha/9mH56KOPMGbMGKSmpmru07FjR3Ts2NF1e+DAgThy5Aj+85//YOjQoZrHTZs2DVOnTnXdzs/PZ9BCuP/idnh2wQ6Mu1D7Necr0o9o+d+8+VBjdNcUJETbq6dF63TI1TOgTSMs2XnCcL/IMPUW/J4a/97vuG1Qa7drXbqr+lqkQ0I5+SVYuisHV/dMRVQ420AReePVX3bjw9UZuKJbilvvKDVqmdTQEHNvNP1aJeDm/i2sXqJP+e0d4/Dhw1i6dCnmz59v+dgBAwbg888/193HbrfDbtduoU7108QBLTGobWO0bhzt98eSDgmFSlv2Wwg0bALw7NjOstuu80gCn/G9mmL+n/JpxFIm33N8HrAcOVOMf/2402378z9Ub5NmWCbMSkfmmSLsOJ6Hf1/TzafXQlSfbMg4gw9XZwAAFm3PwkwTx6h1tw01mWH57M5+mmuO1RS/5YJmz56NxMREXHGF9WXmN2/ejJSUFOMdiRQEQUC7xAa6LeV991jVP4dZeDy9YStpkPLerb0QExGKl8d3w+vX9dA9p9Zq0EqR4TX/hiOtYck8UwRAnoEhIuuufz/d8jFq7z0xdnN5i5AA6E/glwyLw+HA7NmzMXnyZISGyh9i2rRpOHbsGD799FMAwFtvvYVWrVqhS5curiLdefPmYd68ef64NCKfEbQyLAbHyVZMdTtn9c99WyVg67OjTAUjbZs0MNwHACJ8nGExo5JFLEQBQRmv/POyjrCH2kyt7l4TXwKN+CXDsnTpUmRmZuL22293uy8rKwuZmZmu22VlZXj00UfRvXt3DBkyBGvWrMGiRYswfvx4f1wakV+EWpiOrFcWLBsSEtQzJzf2bY6UuAjZts4psZh1ay/MntJX97F9PSRkRiXjFSJLSsor8b8/jiKnoET1fk+Xu1BmWO4b0Q4No8JNHVuTsxa1+CXDMmrUKM1+GHPmzJHdfuyxx/DYY4/54zKIaoy0cM2oy63eRCbpkJDWeeKiwnBtr2aYsXx/9b42AaO7pqCgpFz1GKdaGRJSGTcPlFWqiQLRm0v24v1VB9GsYSTWPH6x2/25RWUenVet6DYQMidmBc98JqIAFmozX3Rrtrmd1nkECFC+xzhvh4dWX8cL47ogfZr8zS60Ft6cgnEZe6LatPj8jL+jZ4tV7z/jYcCi9rfIgIWonpENCRlkD6TvGfqt+dXPIwju6Vnnm460p0JCtB3xkeGKY2shYFEJ0AIgu0wUsIxiiDOFngUsal+WauNLjKcYsBD5QJgks2E02qE7S0iQDglp7AP34SLnbenxDlF0Cwxq462JGRYia4y+WBSUVnh0XtXW/AxYiOoXK9OapfFKt2ZxsvukZ9GqYREEZaM69X0dohgQ6V5PA5ZKh4gFW44hK089LU5UVxn92VZUGv9NlVU43DIqal+WginDwlaTRD4QIqlhaZmgv36QKIrY+NSlyCsuR9P4SNl9siEhnRoWrSEhqUbRdsMC4JrgacAyZ+0hvPDjTjSNj8TvT7gXHhLVVUZ/t+UGU+/yissx9NXl6NsqAf+d3Me1XS1gCYQvNWYxYCHygdAQAV/e1R8/b8/G/Re3091XBNAkxo4mMe6dmqVvVFppYUFQGxKq/nnmzb2wOzsfg9s1Uj22pnkasMz74ygA4FguMyxUvxgNCRkFLL/uyEZecblbg0a1lkgMWIjqmbAQAYPaNsagto0N99WvYTF+rKoaFuVx1Ruu6J6CK7qrd4rWO394iA1tmkRjd3aB8UVYoFp0a+I4rR4URHWd4ZCQzpcAh0NEkUaNi/S9p8X5THAwBSysYSHyAemQkBGva1AFAX1aNfTyJO7aJjbAgDbuWRlvOVR+YeWmtQdOYfrCHbJVZ095OBOCKNh5MyR07ay1mC5Zy2vWygOun6UBy3f3DgIgb8kQ6ILnSokCWJiJ1Qf/eVnVquQvj9de9M9MzUlkWAh6t0xAy0b6tTJq9KZch4fa/FLzovZtMDu/BPtzqjM5N3+4HnPWHsK7K6reXA+fPue6T+sb4A9bj2PM/61GxqlzqvcTBSujpEe5TtHt5sxc2e2Xf97t+tkZr3RvFodGDaqGpE2ufRgQguhSiQKXmW8p941oh13/Go1LLkjS3EcvXnhiTCf0bBGPiQNbAgAGtfUgGyI5/6UXJMruCrMJiI8Ks35OA1o1LP9etAsbMs7gmnd/d23beTwPQPUiiQAQH6l+TQ98tRm7svLxxLxtPrxaotrnaQ2LWjbTuf+WI7mu46Tnt5Idrm2sYSHygVATGRbAu9b49wxri3uGtfX4eADo3bIhvrprAJbvycEjozrgj8NncfOH6wEAYSE2JESbW1fEiq83ZuLLDZmYeXNP2fZK0X3F2fySqrF3aVamWDJMpKbQw54URIHKeFqzesCiVdvy7IId+GpDJto2iXY7P6c1E9UzZoaEzPDnNOS7h7ZBbEQYBrZthIHnszPSJeNDQwS/BCzL95wEADwxb7tsu9p6KIXOgKVSHrCIoqj5rTMQpm4T+ZJxDYt6YKKVzfxqQ9WCwwdOVg2fRoRWf3EKpr+f4MkFEQUw6RuAN6y8dZhcksglSiW7I60PCQuxIVFlqrWvLNqeJbu97Wie2z47s/Jx8X9WYNnuHNc2UQTKdIoMg+j9lsgUo9e01pBQudq8ZRUNo6uHWbWyw388fampc9UkBixEXrh9cGv0ahGvW5dihZUPX6sBi1rBrU0WsAjo1aIhRnb2ze/iqYOnzrm+ETqVlOkFLIxYqG4xek1rDf1UmuiACwBxkjXGtIraA/HvikNCRF54dmxnH5+xZt8kbLIhIRtsNgEfTuqDVk8sqtHrMFJcXok4qBffBtEQPJEpIR4W3er1Z5GSFtdrPVYg/l0xw0IUQJo1jDTe6TwR3i8qKH2zkq70/L97Bnp9bl8q0Sm8DcD3VSKveDokZLartHTmnWaGJQD/sphhIQogXZvGIW18N1OBi+UhIZX3H+mMRulsgU4psdZO7mfHc4vRqnG06n2BmLom8oZRIazW4ocVJmtYpBkWzRmOAfhnxQwLUYC5qV8LDGnfpEYeS1Z0G1r9dhBo6WBlwa5UgF0qkddsij/AY7nFWLEnx7X6slYRutkMS0wEh4SIqAZ5PyAE2CWzm8Ik71CBNtUxt7hc875Au1Yib0lf0aIoYvDLyzBl9kas2FvVIkA7w2LuXUH6RSWYim4ZsBAFKeuzhNxJpzqHSmpYAu29qqzC82nNescSBSJpDCHNmqw/eAaA9tCPViCjJOu/pNHplhkWIgoo0s670gDIaJZCTXHW1ZwrrcD2o3mqrcf1LvWDVQfQ4emfsfbAKX9dIpHPSbOG0qyJc3NZhXc1LNKsilZn/kAsumXAQhSkfDFLKCqsOmCRzjwIlGEWZwZo7YHTGDtjDQak/eY2Q0LvWl/6qWrht8e53hAFEUErYHFt866GRVojo5VhCZC3ABkGLETBymK80i6xgds26TCQNBAIlDeraLt8ImNOQSle/HGnbJuZa1W+v/+47Tj+/vkfXIeIApJ0OKZC5e/SqIalRYL+Su7SDKp2DQswoXczAMDfhrYxvOaawGnNREHKbLwy/95B2HokF6O7JuvuJ12fRPoNTxCs18tIXdIpEb9JWu1bobacwCfph/H8uK6u256kru//cjMAoENSDB4e2cGjayOqCbK/y/Ov9dIK9b5EzgyL0YKG0rtDZNkWwRX0CBDw0jXdcFO/FujRLM6ja/c1ZliI6rheLRritsGtPV6yPjpc/r1mZOck9GuVgPn3DsJ9I4xXj376Ss+7ASszLE7fbjri+tlMhkXUiLjydGYfeWJz5lnszyn06Tmp/pGO7KhlPnMKSt2OeeSbra7Mi1bWxMkmmxFYvT1EsT081IbeLRvKMrG1iRkWoiCl9SHsKa2ApYE91DV0cvCly2Vvdr1aNMSjozqi9bSfVI99dUJ3tG4cjZv6tXBbH8gMtQwLAPzzf9U1KWamX2o9U+GhvnsjPpFfgmveXQsAOPTyFT47L9U/DsnfdlFZdTZFEASIooisvBK3Y+b9eRTX9GwKwDhgkd4vaAwPcVozEfmMb8MVnYAlovp7jbKhFaD+xjaqcxJ2vzAa1/dpDgCwexgYRIUbf6cyM/0yK68Emw6dcdseptXl0wOHTxf57FxUv0kDFmmdlQAgt6hcc6q+c7Xm0BABHZNiNM+vVaguC1isXHANYcBCRADkY+VSXVM9a9MfIZmB5GlgoJVhkTJ75gmz0t22ac2QIPKlt3/bh/dXHjC9v3S2z9Uzf3f9LAjAiQL37IpT9ZCQDd/8TXs9MK0MjDzDYvpyawz/WomC1IOXtEeITcBtg1t5dZ4+LRsCgCsbotSyUTS+vnsAljw81OPHCPNwDFzaiVeL1dS1dCjN7JDQifwSnw/BUf2QU1CCN5bsRdrPu3UX8ZRyaLzWBAjIL67KuKi9dp2ZlzCbgGi79t+OVp+l0AAfEmINC1GQatukAXa/MNrjYMDp8zv7I+PUOXRKVk8hCwLQv00jS+dUvtd5eo0litkQl3VJwq87Tsi2Sb8sZueVoEFEKBpoFOtmni7CJ+mHJNdl/Kb8afohPLtgB+4f0Q6PXtbR7f6P12Tg1x3ZuGd4dQGywyGqDp9RcBNFEW//th+tGkdh3IVNTR0jnYJcVumQZR61aPV/swlAUVlVwBIbEYpThWWy+4vPB0QhNkG3jkUrsWhU+1LbGLAQBTFvgxWgaujmAj+vzmz2m6XbcWXy4yJV3+yr3mRP5JdgQNpviAwLwa8PDcW/FP1aAOD699ORnV+dUjfz/D27YAcAYMby/aoBi/NxpMNXlaIIW0BWAZA3/jh8Fm8u3QsApgMWaRBQbnKZiEqtDItQXYQbExHmFrA4/85CQwS3DMl1vZvh2z+Oul2T7FoDMKsixSEhItLlSZ8T5TEn8rXH3fUUKwKdSJUiXGf6/I/DZ13HPPLtFizddcJt32zFdfjy7flcafW1mu04SsHlVKH7dGIj0uEdrVWW3Y7ReP0IguAKWGIj3P8WSlwZFveP9nDZauzqr/yG0eGmrq+2MGAhIl2efOlSHnPnEM86ZSbFRshuR4S5v2VtzDiDS99YiUXbslzbjueaC5DMrm5rhnSpBK0aBApuai+Xc6UV+H3/KVlHWilp8Gq0EOd3m4/i0jdWYv9J7V4+ziGhmIgwt/veW1FV2KtWbxUq67Ei/wP99zVdcV3vZrisi35zydrm84Bl+vTpEARB9i85Wf9JWLlyJXr37o2IiAi0adMGs2bN8vVlEZGHzMQrRoW/XZvG4Z8qwyl6hnVogmmXd5JtUxsSKiitwP6cQizaXh2wmJ1GvSurwNI16ZF+RhhlWCodIj5ak4G/juX57PHJ/9QC0dvnbMQt/12Pd1eozwKSvhZKDQKWh7/eiv05hcgt0m5oWD0k5J5hOX2uaoho9T73xT6lWRflkNAt/Vvitet6INSH0/z9wS8Zli5duiArK8v1b/v27Zr7ZmRk4PLLL8eQIUOwefNmPPnkk3jwwQcxb948f1waEVlkJsPyzBWdsdhgFpGVXixTBrXCJ7f3Q2KMPMMiDVgaN9BOX5stHpz351Hsz/Fd0OJktGjut5uO4IUfd+LKd9b4/LHJf9QC0fUZVf19tBojWsmwGHE4RBSVOjMs5ktQBQGQlmtp1aoE4grNUn4JWEJDQ5GcnOz616RJE819Z82ahRYtWuCtt97CBRdcgDvvvBO33347/vOf//jj0ojID2w2AR0kjarU3g/tJmZHOD02ujob88K4Lq6fIyWFrclx8mBGysow1oaMs5r3nbOwOKL0o0yraNJpOzMrQUn6v1VZZ6L1kjPKsOSXlOPfi3aayrZViqKs6NasEEGQZVi0ZgkF+CQh/wQs+/btQ2pqKlq3bo0bb7wRBw8e1Nw3PT0do0aNkm277LLLsGnTJpSXa6fFSktLkZ+fL/tHRIHLbmFGk3T2jvRn6ZRQ9RlDVax8U9R6k957ogBdnvvV9HmkwwVGQ0KscQlO0v9vyvonrb4l0uBVLcOS9tMufLg6w1S2rdIhoqhce0jI6UnFUKrNJsgzLCYaxwUinwcs/fv3x6effopff/0VH374IbKzszFo0CCcPn1adf/s7GwkJSXJtiUlJaGiogKnTrmPwzmlpaUhLi7O9a95c/WmV0TkHV81kLKybo+0QFAasEiDFL1+FlYuWWvGxIertL9oOUkDE+nPRgGJ0ZARBSbp/+PNmfLMnNZrTtmHRWnLEfPZtkrJkJByUVKpq3vKp1wrMyyBPn1Zi88DljFjxuDaa69Ft27dcOmll2LRokUAgE8++UTzGOUborPCWe+Nctq0acjLy3P9O3LkiOa+RFSz1DIcejUskwe2lB8v+dsPkxwnHRIy04DLDK0Gb2YmEEm/MUs/mJhhqZuk/9tu+GCd7D6tjyvp/+vJH29wmxqttYaXmkqHiJLyqv0jdJatCFdkM0NsgqkutlrBe6Dw+7Tm6OhodOvWDfv27VO9Pzk5GdnZ2bJtOTk5CA0NRaNG2t017XY7YmNjZf+IyPd89R6ml2G5b0Q77eMkMxcizQ4JWbho5/t4XlE5Hv12K9IPVGWDRRPLS0q/MSuzLdl5Jdifoz491ajGhQKTXqCpNQypDF5/+Uv+eWc5YDnf/TlC5+9J2RDRJsiHPrWGfgJ8RMj/AUtpaSl27dqFlJQU1fsHDhyIJUuWyLYtXrwYffr0QViY+aIiIvKtwe2qvjBcbbKjpxG9dYH0EhJaNSxqPVmcrLzvOr9VvrZ4N/73x1Hc9OH5b84WMyzlknEehyhiQNpvuPSNlchRaZqn1RiMApte3x6tD3tlwKKMpc12vwWA/67JwK6sqnpNe1gImidEqu6n/HKgXKpCa0go0JeT8HnA8uijj2LlypXIyMjA+vXrMWHCBOTn52Py5MkAqoZyJk2a5Nr/nnvuweHDhzF16lTs2rULH3/8MT766CM8+uijvr40IrLgs9v7Y8fzlyE1Xv1NUZfK+55ehkUv+JDVsISby7BY+dYqCMC2o7lYd/CMbLvet+lzpRVYtC0LuUXVrdGlywhIP6T+Ou5eo6CxMLZ8H4eIt3/bh3UH1ev/qObpva40i24VAYsyWC0z82KQOJFfNaQUEWrDskeG4+d/DHHbJ1QReKTGR8quT2uWUCAueCjl87WEjh49iptuugmnTp1CkyZNMGDAAKxbtw4tW1aNUWdlZSEzs3q+euvWrfHTTz/h4YcfxsyZM5Gamoq3334b1157ra8vjYgssNkERGssImhE7W1PK2C59IIkxEdp91TRKrrVC4CKysyvXXToVBH+MXeL23a9JMhj87Zh0bYs2YKRRZJlBKTBjnN13Zd/3o25GzPx/FVdTNWwzPvzKN5YUrVuzaGXrzDcn/xPN2DR2K4MWCocIsoqHHCIIiLCQiwF11L2sBCEhdhwQUoserds6FqaIjzE5hZ4pCi+dATrkJDPA5a5c+fq3j9nzhy3bcOGDcOff/7p60shogCi1ehtQu9museFatSw6A0xKdcg0vOHYraHk15I4VwGYHd2ddO5YkmQVC751lxQUtWeYdbKqk6on6w95LbkgBqt+pf8knLMWLYfV/VIRdemcYbnId8pV2RDZMGI1pCQIjitqBQx6OXfkF9Sge3TR3kcsEhrWKSrjqsF8v1aJyC/uLpNiFZxbb0vuiWi+kcttdysYRR6t2xo4lj5bembaES4+vCQ0plzZZr3KamtJL0nuwCZZ4pMnwOQNwWT1rbkl8ibzx0+XYSfFYWXarQ+yNJ+2o0PVh1kl9xaoOyjIr2t9WGvrHspKa/EqcIylFU4cORMkVcZFid536Lq6/jqrgF46NL2uLlfC9nfFTMsREQGbh3QwpW61qIcf5feNNs4TqlhVBjOaqzPUqoSsFz21irT51YjnT1UUFIh+1A6bTKYqtCobdipUhNDNUPZR+Wln3a5ftb6rFf+fyySvd4Et6yNWdK6L61GiwPbNsLAto3OP5L24oeuqwnwDAsDFiKqMWqlG3oZFeVtaX+JKJ0Mi1KrxtE4m5mrep+zr4UvSb95z1p5AA3sxtdaXFaJiLDq+oMKje5ynGBUe5Qzej5bd9j1s9pn/dYjubjr002ybf9dXd2Q0Jv4QDokqtVoUUr6WFqZlFaNoj2/oBrAISEiqjFm2o8oAxbpTekbs96QkJLeuivOvha+pBw6+M/ivbr75+SX4IJnf8Ftcza6tml98zbTH4aqG5B6690V+zH45WU4nltsUHTrHgU8+u1Wt23S/6/eXKM0wyKt89Jq0Ci9Oq1MSr/WCXjpmm6Ye/cAj6/LnxiwEJHPaX1xVHt7Vu6rHF+XfhBI70s2UbjqFKuz7opaDYu31Ba50/P9lmMAgBV7Trq2aXXLra2ec6cLS/HNxiOWFoSsLf9dfRD9XvoNB0+qFy47nTlXhkkfb3AVUat59Zc9OJZbjBd+3IlslZ46TmoxgFGDwLIKz/9nSjMs0rb7WhkWs27u3wID2mg3ba1NDFiIqMa0ahTltq1JjF12u1Dxgdg2sSpN7Zyu+fL4brh7aBv0a51g+nF1MywWhoRueD8dmw6dMdxPbc0Yq6wWY1aeny7rL5Nnb8Bj87bhmQV/+e0xzDCTlXhx0S6cLCjFCz/u1N1v+sIdWLX3JO770niW6s9/ZePXHSc075dmLcxmTm74IN3UfmpkGRbpkFCoVn2Kxw8VMFjDQkQ+1zlVfamMPq0S8Oq13dG6STROF5bh8Olz6NlCf+ZQVHgotj43yjX74cZ+LSxfj14NiZUp0OszzmDCLOMPmZnL9ps+JyDPmhw6dQ6tGkdrFt1qfRZePfN3HDp9Dk3jI9G3VQJeuLqr6n5bjuRixrJ9mHb5BWjbpIHpa/zrWFWH1UXbsvDG9ReaPg4AsvKKse7gaVzZPdWrDMA3m47glZ934+MpfdGjebzh/nr1Pv9dfRALtx73+FqUnPFAWYUD42b+jtaNoww7LheUaGer7KE23UydPMNS/Uj7TqhnlaysYB6oGLAQkc/8+MBFWLXvJG4f3Fpzn+v7qq+s/sLVXfHM93/hpn7u98dFerdMR5RkZduOSTHYc6K6f4o/shLS8xtxOORVKcP/swKHXr5Cp+jW/VNYFEVsP1Y1e2h3dgF2Zxe4ApaDJwsRGR6ClLiq5mFXz/wdAHDodBGWTh1m+jqdPPmmfvn/rcbZonKcyC/FPcPaWj/BeY/9bxsA4KGvt2D5o8MN91e71ofmbsaBk+dw5Ky1aetmH2vjoTPYlZXvaqHvqQb2UJRWaM8okwYp0gyL1eHIYMKAhYh8pmvTOI+bmd3avwUubBaPDsnmv/UbmT62My7vluKqEQGAhy5tj13ZBXj7N/UFWT0RHxWGXI1p00bKKh3YojKDycp0V7V6F1EUkVdcjotfXwnAvVuuUX2HLzmnlC/fneNVwOJUVGaujkZt+u73W9SzKgdOFlrKOCk5H8qbmiibUJ0Vat04WnUK/JRBrTC0Q2PZNmnwMmVQK93rC2asYSGigCAIAro1i9PtYGtV6yYNkBgbgUhJhiUsxIa/++BDUyreiwzQO8v24Zcd7o3kpBkWo5oItZqZknIHjp4tdt0uVcyG8rTc05uhBa2GZUBVB181DoeIVXtPypoBag2XKSkf7YBOkHbJ6yuRV1SOt5buxfXvp1suLnY+L95kOKTDZfFRYdjw1CWy+xs3sOPRyzri4k5Jsu3SDMvorskeP36gY8BCREHrghT1Whkn5xu5dJZQWKgNkeEhmDywpc+uI05nLSQjM5cfcNtWUFIuy7BIMyhqsYvasFZhaYWsTbuyXsJ5nmO5xTW2erRWw7IPVh1A9+mLMf/Po273fb3pCCZ9vAFXzaju7Gu2qFn6cH8cPoNLzmebtHyafghvLd2HDRlnsOHQGc2ZWoDKbLbzN610WVZq3KC6AN0eGoLEmOqZcEM7NMH6Jy9xW3m56lrUC3Dl1xf8KRYGLEQUtL67dxDm3ztI8/4QV8BSnQEJO7/NygKJRrzJsLRUmTk1+eMNsiCiwiHix23HsWJPjmoNi9oH+KJtxzH79wzXbbUCzx+3Hcfgl5fhqe/Nz/wx+7n3zaYjePTbraiQXNua/afw9Pfb3QKkl37aDQB4RKVvyU/bq6YcS7NF0hlUlQ4RRzXrUaovdoHGUJDU60uq++XkFZW7ZaWkujaNwz8v6+i6ve1oHu757A9k5RVrHmOka9PqANyuWME8RNDOUEn7sIRqNY7z+KoCB2tYiChoRYSFoH2idt2BK8MiCSjCzmcdinzYf6VhlOcBi9qsmT8zc2XrLu07UYj7v9wMAGin8vuqZVim/yCf0lugMuTiXA36qw2ZSBvfzdT1mv3gcxbIDm4n7+nx+bpMDG3fBKO6uA9dhNncnwu1jJJ0SOihr7fgh63H8eqE7jhwshDX9qpeTFP6+W515fEXF+1EmybanV8FAD0VM5V+2ZGN8D2e5wHGXdjUNXVaOTSqlwTTKsCVqgMJFgYsRBTcQiUfcpFhIbJpys438rhIeQ0LABT5sAGala67SlqrMkttlPR+Ue5/LLcYF72y3PAcahkWrTqN33adwLT52/H46E54Y8le3Nzf+lRyp7Pn3AOlU4XqwybSTIGTWmdf6YKCP5yfmuwMkN5fqd76ftvRXFPXK73Gq2b8rnm/TVDPZng662zxw0NlwYayY61aZs3JTGt+tVWcg03w/wZEVK9Jv11G25XfSqve5KUZFueb+zmDIaHOBvUxUifyS03va5Z0kch/6TRAe8Og7b+TWoZFet2vL97j+vC/45NNyCkoxSPfbsWx3GK89uses5ftRu1jtkxjqEUrO6DmeG4xnvpuu+4+zpqZPzPP4vf9p02f2wxBEHSLiK2IDg9Bh6QY2fR75ZCQHmnQrhb0AcD4ns3Qo3k8Hri4necXWssYsBBRUJN+yI3sLJ894fx2L61hcU47LTYIWKx0qx3SvrHxTn6i1a9FafHOEzhVqB1YvbNsPx74arNhh91zZZXYe6LAdKGu2jRfrZk0ahkLrcTCA19txhfrM3Uf25lhWb33lP5FeuCSCxJ9FrA4hymjJAG3skBZrdbJSRqkqA2rAVVZwAX3DcYjozqq3h8MGLAQUVCzKQKWz+/o77p9YYt4AFW1Lk7O2RLSFHvT+Ei380o/aNWWFHB64/oeuLZ3M837pYWZ/hBisjhh/p/HcOkb+rNkAGDsO2sM9xn15ir0+NdiXPrGSnyz8Yjb/dJp2GoBi1ZQpJZh0QpYth7JNbxO5//rs0Wez9xR8383Xoi7hrRxdV/2lrMmJ0ryOnXOUJp79wDc0Kc5/nlZJ83jZTUsPrqmQMSAhYjqjOjwUFzUvjF2vzAam56+VDZN9J+XdcT4Xk3R63wQkza+Gxo3CMer13ZX7XMi/aAd36sZPr29n+pjXn1hU0SHa5cDaq2e6ys2C9/yzTS3251trktvQUkF9ucU4rF529yyLdIMiloma8nOE/h83WF8sOqArOYjp6AUV76zWjcTZIXzmfFmqrFU0/hIfDylD8Zd2BRhITZckGx+2FCPc/0saYbJGbAMaNMIr0zortvtObSeBCwsuiWioHf1hak4erbYNbMmIixEllUBgPtGyMfuuzeLx8anLoUgCK7ZMlLSD9oQm4BGDdx7rXzzt4GGAYO/AxazGRZ/Kqt0IMJW9XyXlFfihGRVY7Xhn61H87D1aNVSAsqOvn8dy8fM5fvx3NguANSLbgF54a0WQRCwfE+O12sGXX1hKm7s576Ksc0m4KPJfXDHJ5s0j/3sjn741w870SEpBou2a68KraTXA0aP1pBQXcCAhYiC3ls39vToOLXhIacSyQetTRBUpxP3kUw91iKdnhoXGYa8Ys9a+Ks5fPqcpQyLv+w4no8Hv9qM2wa3wqyVB2SzgIwWl1yzz72+xLmCdk5BCdYdNF4dW8sPW4+7Cok91biBXff1ZfT8D27bGEumDsMHqw7USMBSlzMsdTcUIyIyKSHaPXsiALixb3MkRIfjhr7NVZcMMBMsSKeTPnxpezw6qoNX1yp11YzfDdv214Rr31uLY7nFeHHRLrcpy4U6KxIDQPpB99k7ztqQa2au9d1Fnhdv0DNHOTuskcprQ8oow+V8jUiHvq7olqJ7DABUWvj/Kt3Vm9WwA13d/c2IiExKlRTdfjipDxo3CMfs2/ri5Wu7Y8OTl7gCGr2uulqkQ0LhoSFo48UCe0p5xeU+7djrD4Ue9LsJsQkQRRHHcj3vGqsl1GDIZJJiyYaG0foBjtmZQjf1a4Hk2AjceVFrvDqhO967pRc+ntIHAHBZlyS3/VsmaBd6K0mHzaxMDQ82HBIionqvS2oslu3OAVA10+jSCy51DRdJCyF7tWiI8FCbanOwz+/oj1s/Wu+2PVwWsNg0Z714ypNGZUmxdr/0jlFT4EHAEmoTcOSMe7AyeWBLfJJ+2KvrMfpAVxa3xkfqZ1ik048FQXtWU6MGdqRPu9j1uhpzPsuy7JFhsoD5q7sGYNnuE5gyuJXu40pJH9NXU60DETMsRFTv/X14W4zqnIT/XNcDgP5CcVqfBxe1b4xDL1+BxoriXOlQUliIoFlE6qkTBSXGOyk01FisUW16t7cKNVZh1hNisyE73/33irLYXl/93NX/A+8a0trtfmXAYlTcKz1fapz+86f2umrTpIGsQHxg20Z46orOllYtl15hXVjkUAsDFiKq96LCQ/HBpD6YoNNPxUlrxWGnF8Z1df38wcTeSImvXnFXEAS3NWE6p8QiI+1yaxcssTkz1/IxWlNkYyJ8n3RXWxLAyLHcYtz7xZ9u28NDbHjq8gu8uh5pUWrvlglu98cqnpv+rd33kZKWjEgLsx+4uB3WPnGxh1dpTQCUMdUIBixERBYYBSyjuybjizv7Y9PTl2JUl2S0aVy9gN6ZwlK3ItmeLeIhCIJs3Ru1b/5WdEqOwbNXdta8X6vw1B7m+ZpIWnIKrA89/bD1uGovlrAQAXcNbYNfHhri8fVIMyIRKu3vpcHc1Rem4tYBLd32kas+X1tJfdLANo1kQz3+5OusXaBiDQsRkQVGJQKCIGBwu8ay2w9e3A7fbzmOy7un4Pf98mm8zm/0ax6/GCv3nETvlg2xKytf8/yxEaHIN8haLHpwCEJsAk7kl+D9VQfd7ldrgQ8AbZtEm+ogW1uc1601pAUAvVrE40+drJO0T4k9NATz/j4I+04U4KsNmYiPCpet6nzVhamGC1uelTSla924ulBW6zkmzzFgISKywJMagamjOmLq+TVcpAmWxg3suOOiqmxK0/hI16rIu7OrA5Ypg1phztpDAIB3buqJXi0bYvDLy1Qf57t7ByEmIsyVRXh8dCdc16cZLn1jlWy/0nL1Qt2nr+iM47nFXvU+8SdnwaxahqhRdDi6NYvD+xN7Y94fx/CkxsKINkWGpWeLhujdsiFu6NscAGSzrswMtbRuUp1BayAZUqvJfij1ZUiIAQsRkQXeTsKQ1rBsePISw14uj43uiFaNolBQUoGxPVI193v+qi7o2ULeyM5mE9AuMcZtX62HTIgOx9y7B+KHrcfxwFebda+rNjh7jCgLUts2icZvjwx33VbrSuzUND7SlcFSW2NKOg3dTO+2tk0a4Nt7BiI5NgI7judVX2sd7jhbW/iMEhFZ4O20UemHqZnGc6E2G6YMbo0HLmmvu5+Vjrfje+kXF6tN/dVLLMUoZu80jArDoZevwN+GtTF9TWZIn/u5dw9w/azsRaO1GvTFnRLxiKRxn3L5BkA+lGO2KV/fVglonhAlO1/NZljqR4qFAQsRkQXeThsd3qEJ7h3eFjNu1m73Ln0MsysCl+g0kJMuApkaF4HhHZtgZGf3ZmVOavUXQ9s3wc39W2CUynHjezWVBTTO1YcvbBZveN1GzficQ2aA/LmQruujDFi0PsD/O6mPrHOtWtGt7Dy697qLDJNPYa8pvRSZtbqKQ0JERBZ4OyQkCAIeG91Jfx/F/mbodZT95aEh2Hk8Hxe1a4xKUURYiA3Ks14nmdKtlmGJCg/BS9d0w87j+Vi88wQA4NVru0MQgLE9UnH7Ra0x7LUVAIByR1WGo4HBNOkQm4BeLRpiz4ujMerNVTiRX+JaR8jpvhHt8NGajPPXpR5gNFBkeEZ3TcatA1rg83WZsu02myB7PsMNCmOt9qWRZVhqcEhoULvG+GhyH9kspbqIAQsRkQVG05p9wegh/nxmJF76aRf+98dR17ZzOgFL4wZ2DO3QBADgDFVaSaZbf3lnf/SSLOSoNuzlnC0TJyl4TYmPwJD2Vedt2aj6fM4VmGMi9Nvah0tqUpY9Mhw2AVi49Tj+MXdL1bUKVcNLTl2aytf5+eT2fkj7aRdeuba7bLs9NAQvXt0Nl3RKwm1zNgIAfnqwaiq0NKuiNQPoq7sG4MjZInRtGqd7/UrS89X0IoSXXKCdMasrfB6wpKWlYf78+di9ezciIyMxaNAgvPLKK+jYsaPmMStWrMCIESPctu/atQudOul/EyEiqkn3DGuL5xbuwOXdkv32GIJb/kMuITocr03ojodHdnDNGEqKjdA9RumBi9vhzLkyXNUjFYMk07AB9QyLc7gjXtKnRGtFYed2ZeZDSbpsgTNIGt4x0bXtf38fBEEQsHTqMGTnlaBTsjxgGdahCYadD8TUjOiUiIy0yyGK1TU+MRFhePumnrAJVQ0D1Qxs2wgD0Uj1Pj3yISFWXPiazwOWlStX4r777kPfvn1RUVGBp556CqNGjcLOnTsRHR2te+yePXsQG1v9gmzSRPuFSERUGyYNbIm+rRLQPsl/6fcog94fQNVQUdP4SHx+R38s3XUCEwcaNTiTi4kIcy1FoKSWYXFek/TalLUjHZNisOdEgSubEysZErqlfwtsPHQGUwa1dk05lgYsTtIgx1mK0i6xgayLrBXKpnwAcJXObCtv2CXZm5rIxNU3Pg9YfvnlF9nt2bNnIzExEX/88QeGDh2qe2xiYiLi4+N9fUlERD4jCAI6p8Ya7+iFoR2qimK7phoPSVzUvjEuat/YcD8r1IYznNkDaQ1IpGKWzSe398P//jiCm/pV9ZNJiA5Hy0ZRKCqrxD3D2uLf13QDAMzdmIltR/NwrcpspRCbgNaNo5GVV4zOKf59nn1NWhPjqCczd2qS32tY8vKq5qUnJOivxwAAPXv2RElJCTp37oynn35adZjIqbS0FKWl1a2b8/O1O0MSEQWTEJuADyf1qcXHd898JEqGnF6d0B3bjua6Dcckx0Xg/ourp1+Hhtjw60NDEWITZEMkn9zWD2sPnMalnROhZvHDQ1FRKRp2mQ00cZFh6NOyIcorHWgimZlFviGIfpzALYoixo0bh7Nnz2L16tWa++3ZswerVq1C7969UVpais8++wyzZs3CihUrNLMy06dPx/PPP++2PS8vTzasRERE1vx1LA9XvrMGAHD74NY4UVCCN6+/UHUIh+REUZTVzJCx/Px8xMXFGX5++zVgue+++7Bo0SKsWbMGzZoZr4IqNXbsWAiCgIULF6rer5Zhad68OQMWIiIv7crKx5j/q/qSuebxEWjWMMrgCCLPmQ1Y/BYuP/DAA1i4cCGWL19uOVgBgAEDBmDfvn2a99vtdsTGxsr+ERGR92w6dSpEtcXnNSyiKOKBBx7Ad999hxUrVqB1a8+WSd+8eTNSUlJ8fHVERGSkwlHdvE2tfT1RbfB5wHLffffhyy+/xIIFCxATE4Ps7GwAQFxcHCIjq7oGTps2DceOHcOnn34KAHjrrbfQqlUrdOnSBWVlZfj8888xb948zJs3z9eXR0REBpyN3wAGLBQ4fB6wvPfeewCA4cOHy7bPnj0bU6ZMAQBkZWUhM7O6ZXJZWRkeffRRHDt2DJGRkejSpQsWLVqEyy+/3NeXR0REBhpLFmj0drFHIl/xa9FtTTJbtENERMZ++SsL8VHhskUGifzB7Oc31xIiIiI3o7uyhpACCyfVExERUcBjwEJEREQBjwELERERBTwGLERERBTwGLAQERFRwGPAQkRERAGPAQsREREFPAYsREREFPAYsBAREVHAY8BCREREAY8BCxEREQU8BixEREQU8BiwEBERUcCrM6s1i6IIoGqZaiIiIgoOzs9t5+e4ljoTsBQUFAAAmjdvXstXQkRERFYVFBQgLi5O835BNAppgoTD4cDx48cRExMDQRB8dt78/Hw0b94cR44cQWxsrM/OWxfxubKGz5d5fK7M43NlHp8r8/z5XImiiIKCAqSmpsJm065UqTMZFpvNhmbNmvnt/LGxsXxBm8Tnyho+X+bxuTKPz5V5fK7M89dzpZdZcWLRLREREQU8BixEREQU8BiwGLDb7Xjuuedgt9tr+1ICHp8ra/h8mcfnyjw+V+bxuTIvEJ6rOlN0S0RERHUXMyxEREQU8BiwEBERUcBjwEJEREQBjwELERERBTwGLCquuuoqtGjRAhEREUhJScHEiRNx/Phx3WNEUcT06dORmpqKyMhIDB8+HDt27KihK64dhw4dwh133IHWrVsjMjISbdu2xXPPPYeysjLd46ZMmQJBEGT/BgwYUENXXTs8fa7q4+sKAP79739j0KBBiIqKQnx8vKlj6uPrCvDsuaqvrysAOHv2LCZOnIi4uDjExcVh4sSJyM3N1T2mvry23n33XbRu3RoRERHo3bs3Vq9erbv/ypUr0bt3b0RERKBNmzaYNWuWX6+PAYuKESNG4JtvvsGePXswb948HDhwABMmTNA95tVXX8Ubb7yBGTNmYOPGjUhOTsbIkSNdaxzVRbt374bD4cD777+PHTt24M0338SsWbPw5JNPGh47evRoZGVluf799NNPNXDFtcfT56o+vq4AoKysDNdddx3+/ve/Wzquvr2uAM+eq/r6ugKAm2++GVu2bMEvv/yCX375BVu2bMHEiRMNj6vrr62vv/4aDz30EJ566ils3rwZQ4YMwZgxY5CZmam6f0ZGBi6//HIMGTIEmzdvxpNPPokHH3wQ8+bN899FimRowYIFoiAIYllZmer9DodDTE5OFl9++WXXtpKSEjEuLk6cNWtWTV1mQHj11VfF1q1b6+4zefJkcdy4cTVzQQHM6Lni60oUZ8+eLcbFxZnat76/rsw+V/X5dbVz504RgLhu3TrXtvT0dBGAuHv3bs3j6sNrq1+/fuI999wj29apUyfxiSeeUN3/scceEzt16iTb9re//U0cMGCA366RGRYDZ86cwRdffIFBgwYhLCxMdZ+MjAxkZ2dj1KhRrm12ux3Dhg3D2rVra+pSA0JeXh4SEhIM91uxYgUSExPRoUMH3HXXXcjJyamBqwssRs8VX1fW8XVlrD6/rtLT0xEXF4f+/fu7tg0YMABxcXGGv3tdfm2VlZXhjz/+kL0mAGDUqFGaz0t6errb/pdddhk2bdqE8vJyv1wnAxYNjz/+OKKjo9GoUSNkZmZiwYIFmvtmZ2cDAJKSkmTbk5KSXPfVBwcOHMA777yDe+65R3e/MWPG4IsvvsCyZcvw+uuvY+PGjbj44otRWlpaQ1da+8w8V3xdWcPXlTn1+XWVnZ2NxMREt+2JiYm6v3tdf22dOnUKlZWVll4T2dnZqvtXVFTg1KlTfrnOehOwTJ8+3a1oSvlv06ZNrv3/+c9/YvPmzVi8eDFCQkIwadIkiAZNgQVBkN0WRdFtWzCw+lwBwPHjxzF69Ghcd911uPPOO3XPf8MNN+CKK65A165dMXbsWPz888/Yu3cvFi1a5M9fyy/8/VwB9ft1ZUV9f11ZVVdeV4C150vtdzT63evSa0uP1deE2v5q230l1C9nDUD3338/brzxRt19WrVq5fq5cePGaNy4MTp06IALLrgAzZs3x7p16zBw4EC345KTkwFURZwpKSmu7Tk5OW4RaDCw+lwdP34cI0aMwMCBA/HBBx9YfryUlBS0bNkS+/bts3xsbfPnc1XfX1feqk+vKyvq2usKMP98bdu2DSdOnHC77+TJk5Z+92B+balp3LgxQkJC3LIpeq+J5ORk1f1DQ0PRqFEjv1xnvQlYnAGIJ5xRo1b6r3Xr1khOTsaSJUvQs2dPAFVjgitXrsQrr7zi2QXXIivP1bFjxzBixAj07t0bs2fPhs1mPWl3+vRpHDlyRPbmGSz8+VzV59eVL9SX15VVde11BZh/vgYOHIi8vDxs2LAB/fr1AwCsX78eeXl5GDRokOnHC+bXlprw8HD07t0bS5YswTXXXOPavmTJEowbN071mIEDB+KHH36QbVu8eDH69OmjWe/pNb+V8wap9evXi++88464efNm8dChQ+KyZcvEiy66SGzbtq1YUlLi2q9jx47i/PnzXbdffvllMS4uTpw/f764fft28aabbhJTUlLE/Pz82vg1asSxY8fEdu3aiRdffLF49OhRMSsry/VPSvpcFRQUiI888oi4du1aMSMjQ1y+fLk4cOBAsWnTpnyuRL6unA4fPixu3rxZfP7558UGDRqImzdvFjdv3iwWFBS49uHrqorV50oU6+/rShRFcfTo0WL37t3F9PR0MT09XezWrZt45ZVXyvapj6+tuXPnimFhYeJHH30k7ty5U3zooYfE6Oho8dChQ6IoiuITTzwhTpw40bX/wYMHxaioKPHhhx8Wd+7cKX700UdiWFiY+L///c9v18iARWHbtm3iiBEjxISEBNFut4utWrUS77nnHvHo0aOy/QCIs2fPdt12OBzic889JyYnJ4t2u10cOnSouH379hq++po1e/ZsEYDqPynpc1VUVCSOGjVKbNKkiRgWFia2aNFCnDx5spiZmVkLv0HN8eS5EsX6+boSxapppGrP1fLly1378HVVxepzJYr193UliqJ4+vRp8ZZbbhFjYmLEmJgY8ZZbbhHPnj0r26e+vrZmzpwptmzZUgwPDxd79eolrly50nXf5MmTxWHDhsn2X7FihdizZ08xPDxcbNWqlfjee+/59foEUTSoJCUiIiKqZfVmlhAREREFLwYsREREFPAYsBAREVHAY8BCREREAY8BCxEREQU8BixEREQU8BiwEBERUcBjwEJEREQBjwELERERBTwGLERERBTwGLAQERFRwGPAQkRERAHv/wGMai+K9Dkr5AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here, we determine visualls that the optimal learning rate is somewhere around the exponent of -1.0\n",
    "# i.e. 10**-1 = 0.1\n",
    "plt.plot(lr_i, loss_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.3079, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global loss\n",
    "emb = C[X] # using minibatches, we are back to [32, 3, 2]\n",
    "h = torch.tanh(emb.view(-1, 6) @W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Y) # even better and more efficient than the above\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the optimal learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(42)\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random batches and only feed these batches forward and backward through the model\n",
    "\n",
    "for i in range(10000):\n",
    "\n",
    "    # construct minibatch\n",
    "    ix = torch.randint(0, X.shape[0], (32,)) # Select 32 random indices from our dataset\n",
    "\n",
    "    X_batch = X[ix]\n",
    "    Y_batch = Y[ix]\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[X_batch] # using minibatches, we are back to [32, 3, 2]\n",
    "    h = torch.tanh(emb.view(-1, 6) @W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y_batch) # even better and more efficient than the above\n",
    "\n",
    "    # backward pass / backpropagation\n",
    "    for p in parameters:\n",
    "        p.grad = None # don't forget to .zero_grad() !!!\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    learning_rate = 10**-1 # 0.1 as visually determined\n",
    "    for p in parameters:\n",
    "        p.data += -learning_rate * p.grad \n",
    "    \n",
    "    # print(loss.item()) # NOTE: In this case, this is only the loss for the current batch!!! Not the global loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4732, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global loss\n",
    "emb = C[X] # using minibatches, we are back to [32, 3, 2]\n",
    "h = torch.tanh(emb.view(-1, 6) @W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Y) # even better and more efficient than the above\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train split, dev/validation split, test split\n",
    "# 80%, 10%, 10%\n",
    "# train set is used to train the parameters\n",
    "# validation set is used to train the hyperparameters (test different configurations)\n",
    "# test set is used to evaluate the performance at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Train, Val and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182437, 3]) torch.Size([182437])\n",
      "torch.Size([22781, 3]) torch.Size([22781])\n",
      "torch.Size([22928, 3]) torch.Size([22928])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "def buildDataset(words):\n",
    "    '''\n",
    "    Takes in a list of words and returns it's characters according to the block size as Tensors.\n",
    "    '''\n",
    "    block_size = 3 # context_length; how many characters do we use to support our prediction of the next character?\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in words:\n",
    "        context = [0] * block_size # padded context of 0-tokens (i.e. \".\")\n",
    "        for ch in w + \".\":\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # shift/move the context window one character to the right --> rolling window of context\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(.8 * len(words))\n",
    "n2 = int(.9 * len(words))\n",
    "\n",
    "Xtr, Ytr = buildDataset(words[:n1])\n",
    "Xdev, Ydev = buildDataset(words[n1:n2])\n",
    "Xtest, Ytest = buildDataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(42)\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random batches and only feed these batches forward and backward through the model\n",
    "\n",
    "for i in range(50000):\n",
    "\n",
    "    # construct minibatch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (32,)) # Select 32 random indices from our dataset\n",
    "\n",
    "    X_batch = Xtr[ix]\n",
    "    Y_batch = Ytr[ix]\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[X_batch] # using minibatches, we are back to [32, 3, 2]\n",
    "    h = torch.tanh(emb.view(-1, 6) @W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y_batch) # even better and more efficient than the above\n",
    "\n",
    "    # backward pass / backpropagation\n",
    "    for p in parameters:\n",
    "        p.grad = None # don't forget to .zero_grad() !!!\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    learning_rate = 10**-1 # 0.1 as visually determined\n",
    "    for p in parameters:\n",
    "        p.data += -learning_rate * p.grad \n",
    "    \n",
    "    # print(loss.item()) # NOTE: In this case, this is only the loss for the current batch!!! Not the global loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3553, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global loss across the TRAIN Set\n",
    "emb = C[Xtr] # using minibatches, we are back to [32, 3, 2]\n",
    "h = torch.tanh(emb.view(-1, 6) @W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Ytr) # even better and more efficient than the above\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3646, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global loss across the VALIDATION / DEV Set\n",
    "emb = C[Xdev] # using minibatches, we are back to [32, 3, 2]\n",
    "h = torch.tanh(emb.view(-1, 6) @W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Ydev) # even better and more efficient than the above\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation:\n",
    "# Train loss and dev loss are roughly the same\n",
    "# this means our model is underfitting\n",
    "# our model is very tiny and not able to perfectly learn the complexity of the given problem\n",
    "# therefore we expect performance increases by scaling up the neural network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling up the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we scale up the network, it will take longer to converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(42)\n",
    "C = torch.randn((27, 2), generator=g) # lookup table for embeddings\n",
    "W1 = torch.randn((6, 300), generator=g)\n",
    "b1 = torch.randn(300, generator=g)\n",
    "W2 = torch.randn((300, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10281"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random batches and only feed these batches forward and backward through the model\n",
    "\n",
    "for i in range(150000):\n",
    "\n",
    "    # construct minibatch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (32,)) # Select 32 random indices from our dataset\n",
    "\n",
    "    X_batch = Xtr[ix]\n",
    "    Y_batch = Ytr[ix]\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[X_batch] # using minibatches, we are back to [32, 3, 2]\n",
    "    h = torch.tanh(emb.view(-1, 6) @W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y_batch) # even better and more efficient than the above\n",
    "\n",
    "    # backward pass / backpropagation\n",
    "    for p in parameters:\n",
    "        p.grad = None # don't forget to .zero_grad() !!!\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    if i < 50000:\n",
    "        learning_rate = 10**-1 # 0.1 as visually determined\n",
    "    else:\n",
    "        learning_rate = 0.01\n",
    "\n",
    "    for p in parameters:\n",
    "        p.data += -learning_rate * p.grad \n",
    "    \n",
    "    # print(loss.item()) # NOTE: In this case, this is only the loss for the current batch!!! Not the global loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2275, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global loss across the TRAIN Set\n",
    "emb = C[Xtr] # using minibatches, we are back to [32, 3, 2]\n",
    "h = torch.tanh(emb.view(-1, 6) @W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Ytr) # even better and more efficient than the above\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2553, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global loss across the VALIDATION / DEV Set\n",
    "emb = C[Xdev] # using minibatches, we are back to [32, 3, 2]\n",
    "h = torch.tanh(emb.view(-1, 6) @W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Ydev) # even better and more efficient than the above\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are still underfitting.\n",
    "# Most likely, our 2D vector space for our embeddings is our bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt. figure (figsize=(8,8)) \n",
    "plt.scatter(C[:,0].data, C[:,1].data, s=200)\n",
    "\n",
    "for i in range(C.shape[0]):\n",
    "    plt. text(C[i,0].item(), C[i,1].item(), itos[i], ha=\"center\", va=\"center\", color='white')\n",
    "plt.grid ( 'minor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
