{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of the above was copied from the recent lectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item() # compare if bit-perfect (exactly identical)\n",
    "  app = torch.allclose(dt, t.grad) # compare if approximately close enough; maybe slight differences to floating point variance\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5) # Kaiming Init\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (n,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3448, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "\n",
    "# IMPORTANT NOTE: The gradient HAS TO HAVE THE SAME SHAPE as the input value/vector/matrix\n",
    "dl_by_dl = -1 \n",
    "\n",
    "dl_by_dlogprobs = torch.zeros_like(logprobs) # we need the exact same shape as logprobs, but fill it with 0\n",
    "dl_by_dlogprobs[range(n), Yb] = -1/n # set only the relevant values impacting the loss to the derivative as outlined above\n",
    "assert(dl_by_dlogprobs.shape == logprobs.shape)\n",
    "\n",
    "dl_by_dprobs = (1 / probs) * dl_by_dlogprobs\n",
    "assert(dl_by_dprobs.shape == probs.shape)\n",
    "\n",
    "dl_by_dcounts_sum_inv = (counts * dl_by_dprobs).sum(1, keepdim=True) # sum because we need one gradient per input value\n",
    "assert(dl_by_dcounts_sum_inv.shape == counts_sum_inv.shape)\n",
    "\n",
    "dl_by_dcounts = counts_sum_inv * dl_by_dprobs # this is only the first local gradient for counts, as counts goes into multiple steps\n",
    "assert(dl_by_dcounts.shape == counts.shape)\n",
    "\n",
    "dl_by_dcounts_sum = -(1 / counts_sum **2) * dl_by_dcounts_sum_inv\n",
    "assert(dl_by_dcounts_sum.shape == counts_sum.shape)\n",
    "\n",
    "# counts_sum = counts.sum(1, keepdim=True) ### What is happening here? Let's break it down\n",
    "# counts is a [32, 27] matrix and we sum up all column values (sum(1) = row-wise sum)\n",
    "# therefore, we receive a [32, 1] matrix in counts_sum\n",
    "# this can be generalized as follows\n",
    "# a11 a12 a13 ---> b1 = (a11 + a12 + a13)\n",
    "# a21 a22 a21 ---> b2 = (a21 + a22 + a23)\n",
    "# a31 a32 a33 ---> b3 = (a31 + a32 + a33)\n",
    "# as we can see, all we do is addition\n",
    "# and what did we learn about gradients during addition operations? The gradient simply gets passed along / routed to the previous parts\n",
    "# therefore, the gradient of each matrix value aXY is 1.0 multiplied by the incoming gradient\n",
    "# what do we need? We need a matrix in the shape of [32, 27] that is all 1.0\n",
    "# and then multiply these values by the incoming gradient according to the chain rule\n",
    "dl_by_dcounts += torch.ones_like(counts) * dl_by_dcounts_sum # NOTE: += since gradients need to be aggregated when the value serves as input for multiple operations\n",
    "assert(dl_by_dcounts.shape == counts.shape)\n",
    "\n",
    "dl_by_dnorm_logits = norm_logits.exp() * dl_by_dcounts\n",
    "assert(dl_by_dnorm_logits.shape == norm_logits.shape)\n",
    "\n",
    "dl_by_dlogit_maxes = -1.0 * (torch.ones_like(logit_maxes) * dl_by_dnorm_logits).sum(1, keepdim=True)\n",
    "assert(dl_by_dlogit_maxes.shape == logit_maxes.shape)\n",
    "\n",
    "dl_by_dlogits = torch.ones_like(logits) * dl_by_dnorm_logits\n",
    "assert(dl_by_dlogits.shape == logits.shape)\n",
    "\n",
    "# NOTE: This is a special case since we use tha max values for normalization to allow for numeric stability of our logits\n",
    "# SPECIAL NOTE: You could also do this as a clever one-liner using one-hot:\n",
    "# dl_by_dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dl_by_dlogit_maxes\n",
    "tmp = torch.zeros_like(logits) # set all logit gradients to zero\n",
    "# IMPORTANT: We need to use range(n) instead of : !!!\n",
    "tmp[range(n), logits.max(1).indices] = 1.0 # only set the logit gradients for the MAX logits, since those are used for normalization\n",
    "dl_by_dlogits += tmp * dl_by_dlogit_maxes # chain rule\n",
    "assert(dl_by_dlogits.shape == logits.shape)\n",
    "\n",
    "# How would we go about differentiating logits = h @ W2 + b2?\n",
    "# Let's do this with a simplified example\n",
    "# Assume d = a @b + c where d.shape = [2x2]; a.shape = [2x2]; b.shape = [2x2] and c.shape = [2x1]\n",
    "# Step 1: Matrix Multiplication\n",
    "# Step 2: Derivatives dL / da_ij; Simplify etc.\n",
    "# OR ...\n",
    "# We can simply make the shapes match: \n",
    "# dl_by_dlogits.shape, h.shape, W2.shape, b2.shape\n",
    "# (torch.Size([32, 27]),\n",
    "#  torch.Size([32, 64]),\n",
    "#  torch.Size([64, 27]),\n",
    "#  torch.Size([27]))\n",
    "dl_by_dh = dl_by_dlogits @ W2.T\n",
    "assert(dl_by_dh.shape == h.shape)\n",
    "dl_by_dW2 = h.T @ dl_by_dlogits\n",
    "assert(dl_by_dW2.shape == W2.shape)\n",
    "dl_by_db2 = dl_by_dlogits.sum(0)\n",
    "assert(dl_by_db2.shape == b2.shape)\n",
    "\n",
    "dl_by_dhpreact = (1 - h**2) * dl_by_dh\n",
    "assert(dl_by_dhpreact.shape == hpreact.shape)\n",
    "\n",
    "dl_by_dbngain = (bnraw * dl_by_dhpreact).sum(0, keepdim=True)\n",
    "assert(dl_by_dbngain.shape == bngain.shape)\n",
    "dl_by_dbnraw = dl_by_dhpreact * bngain\n",
    "assert(dl_by_dbnraw.shape == bnraw.shape)\n",
    "dl_by_dbnbias = (dl_by_dhpreact * 1.0).sum(0, keepdim=True) # in addition, we simply pass along the gradient; * 1.0 is not necessary\n",
    "assert(dl_by_dbnbias.shape == bnbias.shape)\n",
    "\n",
    "dl_by_dbndiff =  bnvar_inv * dl_by_dbnraw\n",
    "assert(dl_by_dbndiff.shape == bndiff.shape)\n",
    "dl_by_dbnvar_inv = (bndiff * dl_by_dbnraw).sum(0, keepdim=True)\n",
    "assert(dl_by_dbnvar_inv.shape == bnvar_inv.shape)\n",
    "\n",
    "dl_by_dbnvar = (-0.5 * (bnvar + 1e-5)**-1.5) * dl_by_dbnvar_inv # according to Power Rule\n",
    "assert(dl_by_dbnvar.shape == bnvar.shape)\n",
    "\n",
    "dl_by_dbndiff2 = (1/(n-1)) * torch.ones_like(bndiff2) * dl_by_dbnvar\n",
    "assert(dl_by_dbndiff2.shape == bndiff2.shape)\n",
    "\n",
    "dl_by_dbndiff += (2 * bndiff) * dl_by_dbndiff2 # Power Rule\n",
    "assert(dl_by_dbndiff.shape == bndiff.shape)\n",
    "\n",
    "dl_by_dbnmeani = (-1.0 * dl_by_dbndiff).sum(0, keepdim=True)\n",
    "assert(dl_by_dbnmeani.shape == bnmeani.shape)\n",
    "\n",
    "dl_by_dhprebn = dl_by_dbndiff.clone()\n",
    "assert(dl_by_dhprebn.shape == hprebn.shape)\n",
    "\n",
    "dl_by_dhprebn += 1.0/n * (torch.ones_like(hprebn) * dl_by_dbnmeani)\n",
    "\n",
    "\n",
    "dl_by_dembcat = dl_by_dhprebn @ W1.T\n",
    "dl_by_dW1 = embcat.T @ dl_by_dhprebn\n",
    "dl_by_db1 = dl_by_dhprebn.sum(0)\n",
    "\n",
    "dl_by_demb = dl_by_dembcat.view(emb.shape)\n",
    "\n",
    "dl_by_demb.shape, C.shape, Xb.shape\n",
    "dl_by_dC = torch.zeros_like(C)\n",
    "for k in range (Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dl_by_dC[ix] += dl_by_demb[k, j]\n",
    "\n",
    "# CROSS CHECK OUR CALCULATIONS TO PYTORCH AUTOGRAD FOR VALIDATION\n",
    "cmp('logprobs', dl_by_dlogprobs, logprobs)\n",
    "cmp('probs', dl_by_dprobs, probs)\n",
    "cmp('counts_sum_inv', dl_by_dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dl_by_dcounts_sum, counts_sum)\n",
    "cmp('counts', dl_by_dcounts, counts)\n",
    "cmp('norm_logits', dl_by_dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dl_by_dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dl_by_dlogits, logits)\n",
    "cmp('h', dl_by_dh, h)\n",
    "cmp('W2', dl_by_dW2, W2)\n",
    "cmp('b2', dl_by_db2, b2)\n",
    "cmp('hpreact', dl_by_dhpreact, hpreact)\n",
    "cmp('bngain', dl_by_dbngain, bngain)\n",
    "cmp('bnbias', dl_by_dbnbias, bnbias)\n",
    "cmp('bnraw', dl_by_dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dl_by_dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dl_by_dbnvar, bnvar)\n",
    "cmp('bndiff2', dl_by_dbndiff2, bndiff2)\n",
    "cmp('bndiff', dl_by_dbndiff, bndiff)\n",
    "cmp('bnmeani', dl_by_dbnmeani, bnmeani)\n",
    "cmp('hprebn', dl_by_dhprebn, hprebn)\n",
    "cmp('embcat', dl_by_dembcat, embcat)\n",
    "cmp('W1', dl_by_dW1, W1)\n",
    "cmp('b1', dl_by_db1, b1)\n",
    "cmp('emb', dl_by_demb, emb)\n",
    "cmp('C', dl_by_dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnbias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_by_dhpreact.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3447928428649902 diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dL / dlogprobs \n",
    "logprobs.shape\n",
    "logprobs[range(n), Yb].shape # plug out the probability of each 32 inputs in the batch at the position of the ground truth index Yb\n",
    "\n",
    "# the loss function L is the negative mean of these probabilites, i.e. mean of 32 values\n",
    "# let's see how this would translate to a simpler example\n",
    "# loss = -(a + b + c) / 3\n",
    "# identical to: loss = -1/3a + -1/3b + -1/3c\n",
    "# dL / da = -1/3\n",
    "# or generalized: dL / da = -1/n\n",
    "# but NOTE: the shape of logprobs is [32, 27]! But we only plug out one value per row (instead of 27) --> what happens to the remaining 26 values?\n",
    "# Since we calculate our loss by comparing only the prediction for the ground truth index, the remaining 26 values do NOT impact the loss at all\n",
    "# therefore, intuitively, their gradients will be 0 (since the gradient determines the impact of a value on the loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  counts           --*->\n",
    "#                           probs --log-> logprobs --negative mean->loss\n",
    "# counts_sum_inv    --*->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape\n",
    "\n",
    "# c = a * b, but using tensors\n",
    "# a[3x3] * c[3x1]\n",
    "# a11*b1, a12*b1, a13*b1\n",
    "# a21*b2, a22*b2, a23*b2\n",
    "# a31*b3, a32*b3, a33*b3\n",
    "# c[3x3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1]), torch.Size([32, 27]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_sum_inv.shape, dl_by_dprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 27]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, dl_by_dprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1206, -0.0600,  0.0371, -0.0226,  0.0360, -0.0211,  0.0416,  0.0093,\n",
       "         -0.0270, -0.0887,  0.0359,  0.0001,  0.0117,  0.0369, -0.0627,  0.0138,\n",
       "          0.0366,  0.0308, -0.0280,  0.0122,  0.0058,  0.0283,  0.0157,  0.0405,\n",
       "          0.0401,  0.0016, -0.0033]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.ones_like(logit_maxes) * dl_by_dnorm_logits).sum(0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_by_dlogit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 27]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs.shape, dl_by_dlogprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros_like(logits)[:, logits.max(1, keepdim=True).indices] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64, 27]),\n",
       " torch.Size([27]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_by_dlogits.shape, h.shape, W2.shape, b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpreact.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([1, 64]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_by_dhpreact.shape, bngain.shape, bnraw.shape, bnbias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bndiff * bnvar_inv\n",
    "dl_by_dbnraw.shape, bndiff.shape, bnvar_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bndiff2 derivative\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True)\n",
    "# What happens here is we basically scale bndiff2 by a scalar (1/(n-1)), which is a vector of shape [32]\n",
    "# example\n",
    "# a11 a12\n",
    "# a21 a22\n",
    "# ------>\n",
    "# b1 b2 where\n",
    "# b1 = (1/(n-1)) * (a11 a21)\n",
    "# b2 = (1/(n-1)) * (a12 a22)\n",
    "bndiff2.shape, dl_by_dbnvar.shape\n",
    "dl_by_dbndiff2 = (1/(n-1)) * torch.ones_like(bndiff2) * dl_by_dbnvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bndiff.shape, hprebn.shape, bnmeani.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([32, 30]),\n",
       " torch.Size([30, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hprebn = embcat @ W1 + b1\n",
    "dl_by_dhprebn.shape, embcat.shape, W1.shape, b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embcat = emb.view(emb.shape[0], -1)\n",
    "dl_by_dembcat.shape, emb.shape\n",
    "dl_by_demb = dl_by_dembcat.view(-1, 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb = C[Xb]\n",
    "dl_by_demb.shape, C.shape, Xb.shape\n",
    "dl_by_dC = torch.zeros_like(C)\n",
    "for k in range (Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dl_by_dC[ix] += dl_by_demb[k, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 4.889443516731262e-09\n"
     ]
    }
   ],
   "source": [
    "dlogits = F.softmax(logits, 1) # calculate the probabilities for each character across all 32 examples in mini batch\n",
    "dlogits[range(n), Yb] -= 1 # subtract 1.0 from the CORRECT character / ground truth Y\n",
    "dlogits /= n # scale the gradient down by n to arrive at the mean\n",
    "\n",
    "cmp(\"logits\", dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0736, 0.0890, 0.0186, 0.0489, 0.0205, 0.0808, 0.0227, 0.0335, 0.0168,\n",
       "        0.0321, 0.0389, 0.0379, 0.0381, 0.0262, 0.0331, 0.0143, 0.0091, 0.0195,\n",
       "        0.0165, 0.0561, 0.0491, 0.0200, 0.0244, 0.0748, 0.0606, 0.0248, 0.0200],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0] # only for the first element/example in our mini batch of 32 elements\n",
    "# as we can see, the values are almost all equally likely at this state of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0736,  0.0890,  0.0186,  0.0489,  0.0205,  0.0808,  0.0227,  0.0335,\n",
       "        -0.9832,  0.0321,  0.0389,  0.0379,  0.0381,  0.0262,  0.0331,  0.0143,\n",
       "         0.0091,  0.0195,  0.0165,  0.0561,  0.0491,  0.0200,  0.0244,  0.0748,\n",
       "         0.0606,  0.0248,  0.0200], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to find out where we need to fine-tune our model, we identify the\n",
    "dlogits[0] * n # pre-scaling, this is exactly equal to the probabilities of the Softmax, except for the position of the correct element, where we subtracted -1\n",
    "\n",
    "# LET'S CHECK OUT THE MAGIC OF THE CROSS ENTROPY LOSS AND WHAT IT IS DOING IN THE BACKWARD PASS\n",
    "\n",
    "# Why do we do this?\n",
    "# Remember, dlogits are the GRADIENTS and GRADIENTS REPRESENT FORCES\n",
    "# The gradients tell us the direction in which we want to pull or push (\"nudge\") our values\n",
    "# And the direction is simple: We want to push UP on the probabilities of the correct values\n",
    "# And we want to pull DOWN on the probabilities of the incorrect values\n",
    "# And also remember: These sum up to 0.0. Therefore, if we have a high probability on a misprediction AND we have a low probability on the correct prediction, the remaining probabilities will be near 0. Therefore, we can automatically pull down on the incorrect probability by simultaneously pushing up on the correct probability.\n",
    "# Think of this as a pulley-system (\"Kabelzug\") --> When you pull down on on end, the other end will be pushed up and vice versa.\n",
    "# So by pulling down on one logit, we will push up other logits.\n",
    "# Therefore, the more we pull in the direction of the correct probability, the less force we will apply to the remaining incorrect logits.\n",
    "# This is happening in each row\n",
    "# and the amount of push and pull is exactly equalized since the sum of each row is 0.0\n",
    "# The more wrong a prediction, the larger will be the force pulling in the opposite direction. (i.e. the amount to which you mispredict is proportionate to the strength of the pull)\n",
    "\n",
    "# Important fact:\n",
    "# If the predictions came out perfectly correct, we would have 0 probabilities on all but one position, and this position would be the correct one (ground truth).\n",
    "# Therefore, F.softmax(logits, 1) would look something like [0, 0, 0, 1, 0, 0]\n",
    "# If we now subtract 1.0 from the correct prediction, we would end up with all 0.0s in dlogits [0, 0, 0, 0, 0, 0]--> Therefore, we will NOT apply ANY force, since the prediction is already correct\n",
    "# Counter Example: Let's say that our model is 100% predicting the wrong value.\n",
    "# We would arrive at something akin to F.softmax(logits, 1) = [1, 0, 0, 0, 0, 0]\n",
    "# and our dlogits would be [1, 0, 0, -1, 0, 0] <-- REMEMBER: THEY SUM TO 0.0 !!!\n",
    "# What would happen now? In order arrive at the perfect state of all 0s in dlogits, we would heavily pull down on the first index (since the UPDATE step is -learning_rate * gradient) and we would heavily push up on the correct index (-learning_rate * -gradient). Therefore, our neural net will adjust itself by nudging its values in the direction of the gradient.\n",
    "# After one nudge, what will happen?\n",
    "# The probabilities will be updated. F.softmax(logits, 1) after the next iteration might result in [0.8, 0, 0, 0.2, 0, 0]. By subtracting -1 from the correct index to arrive at dlogits = [0.8, 0, 0, -0.8, 0, 0], we will once again pull down on the incorrect prediction and push up on the correct.\n",
    "# After the next iteration, we might end up at F.softmax(logits, 1) = [0.4, 0, 0, 0.6, 0, 0]; dlogits = [0.4, 0, 0, -0.4, 0, 0] and so on until we arrive at a correct prediction, where we will no longer update the gradients since their forces will be all 0s.\n",
    "\n",
    "# Why is this even more amazing?\n",
    "# Due to the backward pass or backpropagation, these gradients are distributed and interconnected throughout the network. Therefore, each push and pull has effects across the entire network, fine-tuning and nudging each parameter in order to arrive at the correct solution as indicated by the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12eb0a6d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(dlogits.detach(), cmap=\"gray\")\n",
    "\n",
    "# This visualizes the above \"pulley\" system.\n",
    "# Black bits are the correct value (ground truth), which is set to minus one\n",
    "# white values are highly positive values, i.e. confident misprediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "\t\n",
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.8153\n",
      "  10000/ 200000: 2.1545\n",
      "  20000/ 200000: 2.3760\n",
      "  30000/ 200000: 2.4294\n",
      "  40000/ 200000: 2.0028\n",
      "  50000/ 200000: 2.3218\n",
      "  60000/ 200000: 2.3408\n",
      "  70000/ 200000: 2.0438\n",
      "  80000/ 200000: 2.3376\n",
      "  90000/ 200000: 2.1722\n",
      " 100000/ 200000: 1.9720\n",
      " 110000/ 200000: 2.3366\n",
      " 120000/ 200000: 2.0260\n",
      " 130000/ 200000: 2.4172\n",
      " 140000/ 200000: 2.3706\n",
      " 150000/ 200000: 2.0861\n",
      " 160000/ 200000: 2.0133\n",
      " 170000/ 200000: 1.8182\n",
      " 180000/ 200000: 1.9759\n",
      " 190000/ 200000: 1.8969\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "  #   if i >= 100: # TODO: delete early breaking when you're ready to train the full net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
